{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pandas as pd \n",
    "import time\n",
    "import root_pandas as rpd\n",
    "from root_pandas import read_root\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 6.2,3.5\n",
    "mpl.rcParams['axes.labelsize'] = 17\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['lines.markersize'] = 6\n",
    "mpl.rcParams['legend.fontsize']= 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class correlation:\n",
    "    def __init__(self, ntriggers, df, df_mixed):\n",
    "        \n",
    "        self.nbins_dphi = 6#32\n",
    "        self.nbins_deta = 18#16\n",
    "        self.nbins_qt   = 20 \n",
    "        self.ntriggers = ntriggers\n",
    "        self.phibins = np.linspace(0, np.pi, self.nbins_dphi+1)#16+1) #was 16+1\n",
    "        #self.phibins  = np.logspace(-1, np.log10(np.pi), self.nbins_dphi+1)\n",
    "        #        self.phibins = np.linspace(-np.pi, np.pi, self.nbins_dphi+1)#16+1) #was 16+1\n",
    "        #self.etabins = np.linspace(-np.pi, np.pi, self.nbins_deta+1)#16+1) #was 16+1\n",
    "        self.etabins = np.linspace(-0.5, 4, self.nbins_deta+1) #was 16+1        \n",
    "        self.qtbins = np.linspace(0, 0.25, self.nbins_qt+1)\n",
    "        \n",
    "        self.bincenters_dphi = [np.mean([x, y]) for (x, y) in zip(self.phibins[:-1], self.phibins[1:])]\n",
    "        self.bincenters_deta = [np.mean([x, y]) for (x, y) in zip(self.etabins[:-1], self.etabins[1:])]\n",
    "        self.bincenters_qt   = [np.mean([x, y]) for (x, y) in zip(self.qtbins[:-1], self.qtbins[1:])]\n",
    "\n",
    "        dphi = list(df['dphi'])\n",
    "        dphi_lab = list(df['dphi_lab'])\n",
    "        qt   = list(df['qt'])\n",
    "        deta = list(df['dy'])\n",
    "        mixed_dphi = list(df_mixed['dphi'])\n",
    "        mixed_dphi_lab = list(df_mixed['dphi_lab'])\n",
    "        mixed_deta = list(df_mixed['dy'])\n",
    "        \n",
    "        self.numberofpairs = df.shape[0]\n",
    "        \n",
    "        #1D correlations\n",
    "        #dphi\n",
    "        self.sameh_dphi =myHisto(dphi, self.phibins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_dphi.norm(ntriggers)   \n",
    "        self.mixh_dphi  =myHisto(mixed_dphi, self.phibins)\n",
    "        norm = sum(self.mixh_dphi.y)#/self.nbins_dphi\n",
    "        self.mixh_dphi.norm(norm)\n",
    "        self.corr_dphi = np.true_divide(self.sameh_dphi.y,self.mixh_dphi.y)\n",
    "        self.corr_dphi_err = np.true_divide(self.sameh_dphi.yerr,self.mixh_dphi.y)\n",
    "\n",
    "        ##qt\n",
    "        self.sameh_qt = myHisto(qt, self.qtbins)\n",
    "        self.sameh_qt.norm(ntriggers)\n",
    "        \n",
    "        #dphi in lab frame\n",
    "        self.sameh_dphi_lab =myHisto(dphi_lab, self.phibins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_dphi_lab.norm(ntriggers)   \n",
    "        self.mixh_dphi_lab  =myHisto(mixed_dphi_lab, self.phibins)\n",
    "        norm = sum(self.mixh_dphi_lab.y)/self.nbins_dphi\n",
    "        self.mixh_dphi_lab.norm(norm)\n",
    "        self.corr_dphi_lab = np.true_divide(self.sameh_dphi_lab.y,self.mixh_dphi_lab.y)\n",
    "        self.corr_dphi_lab_err = np.true_divide(self.sameh_dphi_lab.yerr,self.mixh_dphi_lab.y)\n",
    "        \n",
    "        self.sameh_deta =myHisto(deta, self.etabins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_deta.norm(ntriggers)\n",
    "        self.mixh_deta  =myHisto(mixed_deta, self.etabins)\n",
    "        norm = sum(self.mixh_deta.y)/self.nbins_deta #sum(self.mixh_deta.y)/self.nbins_deta\n",
    "        self.mixh_deta.norm(norm)\n",
    "        #self.corr_deta     = np.true_divide(self.sameh_deta.y,self.mixh_deta.y)\n",
    "        #self.corr_deta_err = np.true_divide(self.sameh_deta.yerr,self.mixh_deta.y)\n",
    "\n",
    "        # 2D correlations\n",
    "        \n",
    "        #self.sameh_2d, self.xedges,self.yedges = np.histogram2d(deta,dphi, [self.etabins,self.phibins])\n",
    "        #self.mixh_2d, self.xedges,self.yedges = np.histogram2d(mixed_deta,mixed_dphi, [self.etabins,self.phibins])\n",
    "\n",
    "        #get correlation function\n",
    "        #self.corr_2d = np.true_divide(self.sameh_2d,self.mixh_2d)\n",
    "        #self.extent = [self.xedges[0], self.xedges[-1], self.yedges[0], self.yedges[-1]]\n",
    "        \n",
    "        #MASS: \n",
    "        self.hmass, self.hmass_x = np.histogram(df['mass'],range=(0.0,2.0),density=True, bins=50)\n",
    "        self.hmass_mix, self.hmass_x = np.histogram(df_mixed['mass'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.hmass_x = (self.hmass_x[1:] + self.hmass_x[:-1])/2.0\n",
    "        \n",
    "        self.hxmass, self.hxmass_x = np.histogram(df['missing_mass'],range=(0.0,2.0),density= True, bins=50)\n",
    "        self.hxmass_mix, self.hxmass_x = np.histogram(df_mixed['missing_mass'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.hxmass_x = (self.hxmass_x[1:] + self.hxmass_x[:-1])/2.0\n",
    "        \n",
    "        #self.t, self.t_x = np.histogram(df['t'],range=(0.0,5.0), density= True, bins=50)\n",
    "        #self.t_mix, self.t_x = np.histogram(df_mixed['t'],range=(0.0,5.0),density=True,bins=50)\n",
    "        #self.t_x = (self.t_x[1:] + self.t_x[:-1])/2.0\n",
    "        \n",
    "        self.dipion_pt, self.dipion_pt_x = np.histogram(df['dipion_pt'],range=(0.0,2.0), density = True, bins=50)\n",
    "        self.dipion_pt_mix, self.dipion_pt_x = np.histogram(df_mixed['dipion_pt'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.dipion_pt_x = (self.dipion_pt_x[1:] + self.dipion_pt_x[:-1])/2.0\n",
    "        \n",
    "\n",
    "    def normalize(self,norma):\n",
    "        #print 'sum entrifes beforoe normalization' ,np.sum(self.corr_dphi)\n",
    "        #print 'requested normalization' , norma\n",
    "        self.corr_dphi     = np.true_divide(self.corr_dphi, norma)\n",
    "        #print ' sum entries after normalization', np.sum(self.corr_dphi)\n",
    "        self.corr_dphi_err = np.true_divide(self.corr_dphi_err,norma)\n",
    "        \n",
    "        self.sameh_dphi_lab.y = np.true_divide(self.sameh_dphi_lab.y,norma)\n",
    "        self.sameh_dphi.y = np.true_divide(self.sameh_dphi.y,norma)\n",
    "        self.sameh_dphi_lab.yerr = np.true_divide(self.sameh_dphi_lab.yerr,norma)\n",
    "        self.sameh_dphi.yerr = np.true_divide(self.sameh_dphi.yerr,norma)\n",
    "        \n",
    "        \n",
    "        return \n",
    "\n",
    "class comparison:\n",
    "    def __init__(self, corr_A, corr_D):\n",
    "        \n",
    "        self.corr_A = corr_A.corr_dphi\n",
    "        self.corr_D = corr_D.corr_dphi\n",
    "        self.err_A  = corr_A.corr_dphi_err\n",
    "        self.err_D  = corr_D.corr_dphi_err\n",
    "        self.dif_err = np.sqrt(np.power(self.err_A,2.0)+np.power(self.err_D,2.0)) #error for difference\n",
    "        self.diff  = np.subtract(self.corr_A,self.corr_D)\n",
    "        self.ratio = np.true_divide(self.corr_A,self.corr_D)\n",
    "        self.ratio_err = np.sqrt(np.power(np.divide(self.err_A,self.corr_A),2.0)+np.power(np.divide(self.err_D,self.corr_D),2.0))*self.ratio \n",
    "        \n",
    "       \n",
    "        \n",
    "class myHisto:\n",
    "    def __init__(self, data, bins):\n",
    "        self.bins = bins\n",
    "        self.y    = np.histogram(data, self.bins)[0]\n",
    "        self.yerr = np.sqrt(self.y)\n",
    "    def norm(self, norm=1.0):\n",
    "        self.y = np.true_divide(self.y, norm)\n",
    "        self.yerr = np.true_divide(self.yerr, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRatio(df_A,df_D,df_trigger_A,df_trigger_D, variable='z_asso',trig_cut = 'z>0.5', pair_cut='',minz=0.05,maxz=0.5,nbins=12):\n",
    "    #get number of pions with z>0.5\n",
    "    norm_A = df_trigger_A.query(trig_cut).shape[0]\n",
    "    norm_D = df_trigger_D.query(trig_cut).shape[0]\n",
    "    y_A, x_conditional = np.histogram(df_A.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "    y_D, x_conditional = np.histogram(df_D.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "    x_conditional = (x_conditional[1:] + x_conditional[:-1])/2.0\n",
    "    err_A = np.true_divide(np.sqrt(y_A),y_A)\n",
    "    err_D = np.true_divide(np.sqrt(y_D),y_D)\n",
    "    y_A = np.true_divide(y_A,norm_A)\n",
    "    y_D = np.true_divide(y_D,norm_D)\n",
    "    ratio_conditional = np.true_divide(y_A,y_D)\n",
    "    error_conditional = np.multiply(ratio_conditional, np.sqrt(np.power(err_A,2.0) + np.power(err_D,2.0)))\n",
    "    \n",
    "    return ratio_conditional,error_conditional,x_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCut(inputDataframe, cut, text=None):\n",
    "    nbeforecut = inputDataframe.shape[0]\n",
    "    cutDataframe = inputDataframe.query(cut)\n",
    "    if text:\n",
    "        print text, cutDataframe.shape[0], ' (%2.2f '%(100.0*cutDataframe.shape[0]/nbeforecut), '%)'\n",
    "    return cutDataframe\n",
    "def applyCuts(fullDataframe,name='default',isMC=False): \n",
    "    dataframe = fullDataframe\n",
    "    print 'Entries before cut ', dataframe.shape[0]\n",
    "#    dataframe.eval('inelasticity = Nu/5.014', inplace=True)\n",
    "    dataframe.eval('inelasticity = Nu/11.0', inplace=True)\n",
    "\n",
    "    dataframe.eval('E = z*Nu', inplace=True)\n",
    "    dataframe.eval('P = sqrt(E*E-0.140*0.140)', inplace=True)\n",
    "    dataframe.eval('x = Q2/(2*0.938*Nu)', inplace=True)\n",
    "  \n",
    "    dataframe = applyCut(dataframe, 'Q2>1.0', 'Q2>1.0 :')\n",
    "    #dataframe = applyCut(dataframe, 'Nu>3.0 and Nu<3.5', '3.0 < Nu < 3.5')\n",
    "    #dataframe = applyCut(dataframe, 'z>0.5', 'z>0.5 :')\n",
    "    #dataframe = applyCut(dataframe, 'P <2.5 ', 'P<2.5 ')\n",
    "\n",
    "    dataframe = applyCut(dataframe, 'inelasticity<0.85','inelasticity < 0.85')\n",
    "    return dataframe\n",
    "\n",
    "def applyCutsPair(fullDataframe,name='default',isMC=False):\n",
    "    print 'Starting election on dipion variables'\n",
    "    dataframe = fullDataframe\n",
    "    dataframe.eval('z_tot = z+z_asso', inplace=True)\n",
    "    dataframe.eval('E_asso = z_asso*Nu', inplace=True)\n",
    "    dataframe.eval('P_asso = sqrt(E_asso*E_asso-0.140*0.140)', inplace=True)\n",
    "    dataframe.eval('qt2 = qt*qt', inplace=True)\n",
    "    dataframe.eval('x = Q2/(2*0.938*Nu)', inplace=True)\n",
    "\n",
    "    dataframe = applyCut(dataframe, 'Q2>1.0', 'Q2>1.0 :')\n",
    "    #dataframe = applyCut(dataframe, 'Nu>3.0 and Nu<3.5', '3.0 < Nu < 3.5')\n",
    "    dataframe = applyCut(dataframe, 'z>0.4', 'z>0.4 :')\n",
    "    #dataframe = applyCut(dataframe, 'P <2.5 ', 'P<2.5 ')\n",
    "\n",
    "    dataframe = applyCut(dataframe, 'pid*pid_asso<0', 'Opposite sign pairs')\n",
    "    \n",
    "    ##Polar angle acceptance, different for \n",
    "    if(isMC==False):\n",
    "        print 'Polar angle acceptance'\n",
    "        dataframe = applyCut(dataframe,'(pid_asso==211 & theta_lab_asso>10 & theta_lab_asso<90)|(pid_asso==-211 & theta_lab_asso>45 & theta_lab_asso<90)')\n",
    "    #dataframe = applyCut(dataframe, '(pid_asso==211 & P_asso>0.200) |(pid_asso==-211 & P_asso>0.300) ', 'pi+ P_asso > 200 MeV, pi- P_asso > 300 MeV')\n",
    "    #dataframe = applyCut(dataframe, 'P_asso<2.5', 'P_asso <2.5 GeV')\n",
    "    #dataframe = applyCut(dataframe, 'mass<1.4', 'mass < 1.4 GeV')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def printPairBreakdown(dataframe):\n",
    "    \n",
    "    print 'Pairs with Leading pi+', dataframe.query('pid==211').shape[0]\n",
    "    print 'Pairs with Leading pi-', dataframe.query('pid==-211').shape[0]\n",
    "    print 'Pairs with Sub-Leading pi+', dataframe.query('pid_asso==211').shape[0]\n",
    "    print 'Pairs with Sub-Leading pi-', dataframe.query('pid_asso==-211').shape[0]\n",
    "    print 'pi+ pi+ pairs',dataframe.query('pid==211 and pid_asso==211').shape[0]\n",
    "    print 'pi- pi- pairs',dataframe.query('pid==-211 and pid_asso==-211').shape[0]\n",
    "    print 'pi+ pi- pairs',dataframe.query('pid==211 and pid_asso==-211').shape[0]\n",
    "    print 'pi- pi+ pairs',dataframe.query('pid==-211 and pid_asso==211').shape[0]\n",
    "    print '//////////////////////////////////////////////////////'\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from Ntuples to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this needs to be read in chunks otherwise it uses all memory. (from https://github.com/scikit-hep/root_pandas)\n",
    "def getdatainChunks(filename,treename):\n",
    "    dataframe =pd.DataFrame()\n",
    "    for df in read_root(filename, treename, chunksize=100000) :\n",
    "        #print df.shape[0]\n",
    "        dataframe = pd.concat([dataframe,df])\n",
    "    \n",
    "    print dataframe.shape[0]\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GiBUU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "df_trigger = {}\n",
    "for target in ['D','Pb']:#,'Fe','C']:\n",
    "    #GiBUU\n",
    "    print target\n",
    "    print '----pairs'\n",
    "    df['GiBUU_%s'%target]= getdatainChunks('GiBUU_Pairs_CLAS12_%s.root'%target, target)\n",
    "    print '----trigger'\n",
    "    df_trigger['GiBUU_%s_trigger'%target]= getdatainChunks('GiBUU_Pairs_CLAS12_%s.root'%target, '%s_trigger'%target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the deuterium datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframees with pairs\n",
    "for key in df.keys():\n",
    "    isMC = False\n",
    "    if 'GiBUU' in key:\n",
    "        isMC=True\n",
    "    print key\n",
    "    \n",
    "    df[key] = applyCuts(df[key],isMC=isMC)\n",
    "    #printPairBreakdown(df[key])\n",
    "    df[key] = applyCutsPair(df[key],isMC=isMC)\n",
    "    print ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply cuts for trigger dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_trigger.keys():\n",
    "    print key\n",
    "    df_trigger[key] = applyCuts(df_trigger[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(8, 6))\n",
    "hb = plt.hexbin(df['GiBUU_D']['x'],df['GiBUU_D']['Q2'],cmap='inferno',bins='log')\n",
    "#axs.axis([xmin, xmax, ymin, ymax])\n",
    "#axs.set_title(\"With a log color scale\")\n",
    "#cb = fig.colorbar(hb, ax=axs)\n",
    "\n",
    "axs.xaxis.set_label_text(\"x\", fontsize=18)\n",
    "axs.yaxis.set_label_text(\"$Q^{2}$ GeV$^{2}$ \", fontsize=18)\n",
    "\n",
    "axs.tick_params(axis=\"x\", labelsize=16)\n",
    "axs.tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('xQ2coverage.png')\n",
    "plt.savefig('xQ2coverage.pdf')\n",
    "#cb.set_label('log10(N)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(8, 6))\n",
    "hb = plt.hexbin(df['GiBUU_D']['Nu'],df['GiBUU_D']['Q2'],cmap='inferno',bins='log')\n",
    "#axs.axis([xmin, xmax, ymin, ymax])\n",
    "#axs.set_title(\"With a log color scale\")\n",
    "#cb = fig.colorbar(hb, ax=axs)\n",
    "\n",
    "axs.xaxis.set_label_text(\"$\\nu$ GeV\", fontsize=18)\n",
    "axs.yaxis.set_label_text(\"$Q^{2}$ GeV$^{2}$ \", fontsize=18)\n",
    "\n",
    "axs.tick_params(axis=\"x\", labelsize=16)\n",
    "axs.tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('xQ2coverage.png')\n",
    "plt.savefig('xQ2coverage.pdf')\n",
    "#cb.set_label('log10(N)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azimuthal correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4,sharex=True,sharey='row', figsize=(14,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "#asso_Edges = [0.06,0.1, 0.15,0.25,0.5]\n",
    "asso_Edges = [0.1,0.15,0.25,0.3,0.5]\n",
    "\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "    \n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f'%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    \n",
    "    corr_D = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "    norma = np.sum(corr_D.sameh_dphi_lab.y)\n",
    "    corr_D.normalize(norma)\n",
    "    #axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi_lab.y, yerr=corr_D.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label='D')\n",
    "    \n",
    "    for target in ['D','Pb']:\n",
    "        corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "        corr.normalize(norma)\n",
    "        axs[0,j].errorbar(corr.bincenters_dphi, corr.sameh_dphi_lab.y, yerr=corr.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label=target)\n",
    "        \n",
    "        ratio = np.true_divide(corr.sameh_dphi_lab.y,corr_D.sameh_dphi_lab.y)\n",
    "        ratio_err = np.sqrt(np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0)\n",
    "                            +np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0))*ratio \n",
    "        \n",
    "        #comp = comparison(corr,corr_D)\n",
    "        if target =='D':\n",
    "            continue\n",
    "        #axs[1,j].fill_between(corr.bincenters_dphi, ratio-ratio_err,ratio+ratio_err,alpha=0.5)\n",
    "        axs[1,j].errorbar(corr.bincenters_dphi, ratio,color='red')\n",
    "\n",
    "        #comp = comparison(corr,corr_D)\n",
    "        #axs[1,j].errorbar(corr.bincenters_dphi, y=ratio, linewidth=3.0,alpha=0.7,fmt='--',label='GiBUU %s'%target)\n",
    "        axs[1,j].legend(loc='best',frameon=False)\n",
    "        axs[1,j].tick_params(axis=\"x\", labelsize=16)\n",
    "        axs[1,j].tick_params(axis=\"y\", labelsize=16)\n",
    "        axs[0,j].tick_params(axis=\"x\", labelsize=16)\n",
    "        axs[0,j].tick_params(axis=\"y\", labelsize=16)\n",
    "        axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=18)\n",
    "        axs[0,j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=16)\n",
    "\n",
    "        plt.ylim([0.55,1.05])\n",
    "\n",
    "\n",
    "axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=18)\n",
    "axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=18)                \n",
    "plt.tight_layout()\n",
    "plt.savefig('CLAS12_AzimuthalCorrelations_zdependence.png')\n",
    "plt.savefig('CLAS12_AzimuthalCorrelations_zdependence.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4,sharex=True,sharey='row', figsize=(14,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "#asso_Edges = [0.06,0.1, 0.15,0.25,0.5]\n",
    "asso_Edges = [0.1,0.15,0.25,0.3,0.5]\n",
    "\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "    \n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f'%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    \n",
    "    corr_D = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "    norma = np.sum(corr_D.sameh_qt.y)\n",
    "    corr_D.normalize(norma)\n",
    "    \n",
    "    for target in ['D','Pb']:\n",
    "        corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "        corr.normalize(norma)\n",
    "        axs[0,j].errorbar(corr.bincenters_qt, corr.sameh_qt.y, yerr=corr.sameh_qt.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label=target)\n",
    "        \n",
    "        ratio = np.true_divide(corr.sameh_qt.y,corr_D.sameh_qt.y)\n",
    "        ratio_err = np.sqrt(np.power(np.divide(corr.sameh_qt.yerr,corr.sameh_qt.y),2.0)\n",
    "                            +np.power(np.divide(corr.sameh_qt.yerr,corr.sameh_qt.y),2.0))*ratio \n",
    "        \n",
    "        if target =='D':\n",
    "            continue\n",
    "        axs[1,j].errorbar(corr.bincenters_qt, ratio,color='red')\n",
    "\n",
    "\n",
    "        axs[1,j].legend(loc='best',frameon=False)\n",
    "        axs[1,j].tick_params(axis=\"x\", labelsize=16)\n",
    "        axs[1,j].tick_params(axis=\"y\", labelsize=16)\n",
    "        axs[0,j].tick_params(axis=\"x\", labelsize=16)\n",
    "        axs[0,j].tick_params(axis=\"y\", labelsize=16)\n",
    "        axs[1,j].xaxis.set_label_text(r'$q_{T}$  [GeV]', fontsize=18)\n",
    "        axs[0,j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=16)\n",
    "\n",
    "        plt.ylim([0.5,1.05])\n",
    "\n",
    "\n",
    "axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=18)\n",
    "axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=18)                \n",
    "plt.tight_layout()\n",
    "plt.savefig('CLAS12_AzimuthalCorrelations_qtdependence.png')\n",
    "plt.savefig('CLAS12_AzimuthalCorrelations_qtdependence.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azimuthal correlations for GiBUU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(1, 2,sharex=True,figsize=(12,6))\n",
    "fig, axs = plt.subplots(2, 3,sharex=True,sharey='row', figsize=(14,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "  \n",
    "\n",
    "##Do Nu bins (for only Pb and only for z-bins)\n",
    "Nu_Edges = [5.0, 7.0, 8.0, 10.0]\n",
    "Nu_bins = [(x, y) for (x, y) in zip(Nu_Edges[:-1], Nu_Edges[1:])]\n",
    "\n",
    "for i, nu_bin in enumerate(Nu_bins):\n",
    "    print i\n",
    "    offset = int(i)*-0.04\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f and Nu>%2.2f and Nu<%2.2f'%(0.5,1.0,nu_bin[0],nu_bin[1])\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f and Nu>%2.2f and Nu<%2.2f'%(0.2,0.50,nu_bin[0],nu_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "\n",
    "    axs[0,i].set_title(r'%2.2f$<\\nu<$%2.2f GeV'%(nu_bin[0], nu_bin[1]), fontsize=16)\n",
    "\n",
    "    ###GIBUU    \n",
    "    corr_D_GiBUU = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "    norma_GiBUU = np.sum(corr_D_GiBUU.sameh_dphi_lab.y)\n",
    "    corr_D_GiBUU.normalize(norma_GiBUU)\n",
    "    y = corr_D_GiBUU.sameh_dphi_lab.y\n",
    "    yerr = corr_D_GiBUU.sameh_dphi_lab.yerr\n",
    "    x = corr_D_GiBUU.bincenters_dphi\n",
    "    axs[0,i].fill_between(x, y-yerr,y+yerr, linewidth=3.0,alpha=0.7,label='D')\n",
    "    \n",
    "    target = 'Pb'\n",
    "    corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "    corr.normalize(norma_GiBUU)\n",
    "    y = corr.sameh_dphi_lab.y\n",
    "    yerr = corr.sameh_dphi_lab.yerr\n",
    "    x  = corr.bincenters_dphi\n",
    "    axs[0,i].fill_between(x, y-yerr,y+yerr, linewidth=3.0,alpha=0.6,label='Pb')\n",
    "    \n",
    "    ##Ratio\n",
    "    \n",
    "    ratio = np.true_divide(corr.sameh_dphi_lab.y,corr_D_GiBUU.sameh_dphi_lab.y)\n",
    "    ratio_err = np.sqrt(np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0)\n",
    "                        +np.power(np.divide(corr_D_GiBUU.sameh_dphi_lab.yerr,corr_D_GiBUU.sameh_dphi_lab.y),2.0))*ratio \n",
    "        \n",
    "    #axs[1,i].fill_between(corr.bincenters_dphi, ratio-ratio_err,ratio+ratio_err,alpha=0.5,color='black')\n",
    "    axs[1,i].errorbar(corr.bincenters_dphi, ratio,color='red')\n",
    "\n",
    "    axs[1,i].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "\n",
    "    plt.ylim([0.5,1.05])\n",
    "    axs[1,i].tick_params(axis=\"x\", labelsize=16)\n",
    "    axs[1,i].tick_params(axis=\"y\", labelsize=16)\n",
    "    axs[0,i].tick_params(axis=\"x\", labelsize=16)\n",
    "    axs[0,i].tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "    #.yticks(fontsize=16)\n",
    "        #labelling\n",
    "#axs[0,0].axhline(y=0.0,color='black',linestyle='--',alpha=0.5)\n",
    "for i in range(3):\n",
    "    axs[1,i].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=18)\n",
    "    axs[0,i].legend(loc='upper left',frameon=False)\n",
    "#axs[0,1].legend(loc='upper left',frameon=False)\n",
    "#axs[0,2].legend(loc='upper left',frameon=False)\n",
    "\n",
    "axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=18)\n",
    "axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=18)\n",
    "#axs[1].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "#axs[0,0].set_title('$z_{1}$> 0.5 , %2.2f < $z_{2}$ < %2.2f'%(asso_Edges[0],asso_Edges[1]), fontsize=16)\n",
    "axs[1,0].legend(loc='best',frameon=False,ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig('CLAS12projection_nudependence.png')  \n",
    "fig.savefig('CLAS12projection_nudependence.pdf')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(1, 2,sharex=True,figsize=(12,6))\n",
    "fig, axs = plt.subplots(2, 3,sharex=True,sharey='row', figsize=(14,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "  \n",
    "\n",
    "##Do Nu bins (for only Pb and only for z-bins)\n",
    "Nu_Edges = [5.0, 7.0, 8.0, 10.0]\n",
    "Nu_bins = [(x, y) for (x, y) in zip(Nu_Edges[:-1], Nu_Edges[1:])]\n",
    "\n",
    "for i, nu_bin in enumerate(Nu_bins):\n",
    "    print i\n",
    "    offset = int(i)*-0.04\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f and Nu>%2.2f and Nu<%2.2f'%(0.5,1.0,nu_bin[0],nu_bin[1])\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f and Nu>%2.2f and Nu<%2.2f'%(0.2,0.50,nu_bin[0],nu_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "\n",
    "    axs[0,i].set_title('%2.2f<Nu<%2.2f'%(nu_bin[0], nu_bin[1]), fontsize=16)\n",
    "\n",
    "    ###GIBUU    \n",
    "    corr_D_GiBUU = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "    norma_GiBUU = np.sum(corr_D_GiBUU.sameh_qt.y)\n",
    "    corr_D_GiBUU.normalize(norma_GiBUU)\n",
    "    y = corr_D_GiBUU.sameh_qt.y\n",
    "    yerr = corr_D_GiBUU.sameh_qt.yerr\n",
    "    x = corr_D_GiBUU.bincenters_qt\n",
    "    axs[0,i].fill_between(x, y-yerr,y+yerr, linewidth=3.0,alpha=0.7,label='D')\n",
    "    \n",
    "    target = 'Pb'\n",
    "    corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "    corr.normalize(norma_GiBUU)\n",
    "    y = corr.sameh_qt.y\n",
    "    yerr = corr.sameh_qt.yerr\n",
    "    x  = corr.bincenters_qt\n",
    "    axs[0,i].fill_between(x, y-yerr,y+yerr, linewidth=3.0,alpha=0.6,label='Pb')\n",
    "    \n",
    "    ##Ratio\n",
    "    \n",
    "    ratio = np.true_divide(corr.sameh_qt.y,corr_D_GiBUU.sameh_qt.y)\n",
    "    ratio_err = np.sqrt(np.power(np.divide(corr.sameh_qt.yerr,corr.sameh_qt.y),2.0)\n",
    "                        +np.power(np.divide(corr_D_GiBUU.sameh_qt.yerr,corr_D_GiBUU.sameh_qt.y),2.0))*ratio \n",
    "        \n",
    "    #axs[1,i].fill_between(corr.bincenters_dphi, ratio-ratio_err,ratio+ratio_err,alpha=0.5,color='black')\n",
    "    axs[1,i].errorbar(corr.bincenters_qt, ratio,color='red')\n",
    "\n",
    "    axs[1,i].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "\n",
    "    plt.ylim([0.50,1.0])\n",
    "    axs[1,i].tick_params(axis=\"x\", labelsize=16)\n",
    "    axs[1,i].tick_params(axis=\"y\", labelsize=16)\n",
    "    axs[0,i].tick_params(axis=\"x\", labelsize=16)\n",
    "    axs[0,i].tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "    #.yticks(fontsize=16)\n",
    "        #labelling\n",
    "#axs[0,0].axhline(y=0.0,color='black',linestyle='--',alpha=0.5)\n",
    "for i in range(3):\n",
    "    axs[1,i].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=18)\n",
    "    axs[0,i].legend(loc='upper left',frameon=False)\n",
    "#axs[0,1].legend(loc='upper left',frameon=False)\n",
    "#axs[0,2].legend(loc='upper left',frameon=False)\n",
    "\n",
    "axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=18)\n",
    "axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=18)\n",
    "#axs[1].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "#axs[0,0].set_title('$z_{1}$> 0.5 , %2.2f < $z_{2}$ < %2.2f'%(asso_Edges[0],asso_Edges[1]), fontsize=16)\n",
    "axs[1,0].legend(loc='best',frameon=False,ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig('CLAS12projection_qt_dependence.png')  \n",
    "fig.savefig('CLAS12projection_qt_dependence.pdf')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azimuthal correlations, various z2 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4,sharex=True,sharey='row', figsize=(14,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "#asso_Edges = [0.05,0.08, 0.15,0.3,0.5]\n",
    "#asso_Edges = [0.08,0.1, 0.15,0.3,0.5]\n",
    "asso_Edges = [0.1, 0.5]\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f'%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    \n",
    "    corr_D = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "    norma = np.sum(corr_D.sameh_dphi_lab.y)\n",
    "    corr_D.normalize(norma)\n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi_lab.y, yerr=corr_D.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label='D')\n",
    "    \n",
    "    for target in ['C','Fe','Pb']:\n",
    "        corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "        corr.normalize(norma)\n",
    "        axs[0,j].errorbar(corr.bincenters_dphi, corr.sameh_dphi_lab.y, yerr=corr.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label=target)\n",
    "        \n",
    "        ratio = np.true_divide(corr.sameh_dphi_lab.y,corr_D.sameh_dphi_lab.y)\n",
    "        ratio_err = np.sqrt(np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0)\n",
    "                            +np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0))*ratio \n",
    "        \n",
    "        #comp = comparison(corr,corr_D)\n",
    "        axs[1,j].fill_between(corr.bincenters_dphi, ratio-ratio_err,ratio+ratio_err,alpha=0.7)\n",
    "        \n",
    "        #labelling\n",
    "        axs[0,j].axhline(y=0.0,color='black',linestyle='--',alpha=0.5)\n",
    "        axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=15)\n",
    "        axs[0,j].legend(loc='best',frameon=False)\n",
    "        axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=16)\n",
    "        axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=16)\n",
    "        axs[1,j].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "        axs[0,j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "#plt.tight_layout()\n",
    "plt.savefig('AzimuthalCorrelations_GiBUU.png')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Mass vs z2 (for fixed z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4,sharex=True,sharey=True, figsize=(14,5), gridspec_kw={'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.2,0.35,0.5]\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "    \n",
    "    \n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    axs[j].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "    axs[j].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "    axs[j].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "    axs[j].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "    plt.xlim([0.3,1.8])\n",
    "\n",
    "    axs[j].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "    #axs[2].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].legend(loc='best',frameon=False)\n",
    "    axs[j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[j].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].yaxis.set_label_text(\"pdf\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dipion Mass vs z2 for fixed z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4,sharex=True, sharey=True,figsize=(14,5), gridspec_kw={'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.15,0.20,0.25]\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.4,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    \n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "\n",
    "    axs[j].plot(corr_C.hmass_x,corr_D.hmass,label='D',alpha=0.8)\n",
    "    #axs[j].plot(corr_C.hmass_x,corr_D_C.hmass_mix,label='D (mix)')\n",
    "\n",
    "    axs[j].plot(corr_C.hmass_x,corr_C.hmass,label='C',alpha=0.8)\n",
    "    axs[j].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe',alpha=0.8)\n",
    "    axs[j].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb',alpha=0.8)\n",
    "    #axs[j].fill(corr_D.hmass_x,corr_D.hmass_mix,label='(mixed)',alpha=0.4)\n",
    "    #axs[j].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='(mixed Pb)',alpha=0.4)\n",
    "\n",
    "\n",
    "    axs[j].axvline(x=0.770,linestyle='--',color='black',alpha=0.4)\n",
    "    #axs[2].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].legend(loc='best',frameon=False)\n",
    "    axs[j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[j].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "    axs[0].yaxis.set_label_text(\"pdf\")\n",
    "    plt.xlim([0.2,2.0])\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Dipion_InvariantMass_anti.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Missing Mass (z1,z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.30,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "               \n",
    "        axs[j,i].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "        axs[j,i].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "        axs[j,i].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "        axs[j,i].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "        #axs[j,i].fill(corr_Pb.hxmass_x,corr_Pb.hxmass_mix,label='(mixed)',alpha=0.4)\n",
    "\n",
    "        plt.xlim([0.0,2.0])\n",
    "\n",
    "        axs[j,i].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "        axs[3,i].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text(r'$\\frac{1}{N_{\\mathrm{trigger}}} \\mathrm{d}N_{\\mathrm{pairs}}$',fontsize=18)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass_2D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Missing Mass (z1,z1+z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.55, 0.65,0.70,0.8,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "            axs[j,i].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "            axs[j,i].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "            axs[j,i].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "            #axs[j,i].fill(corr_D.hxmass_x,corr_D.hxmass_mix,label='(mixed)',alpha=0.4)\n",
    "\n",
    "            plt.xlim([0.0,2.0])\n",
    "\n",
    "            axs[j,i].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "            axs[3,i].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Invariant Mass (z1, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.30,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "               \n",
    "        axs[j,i].plot(corr_D.hmass_x,corr_D.hmass,label='D')\n",
    "        axs[j,i].plot(corr_C.hmass_x,corr_C.hmass,label='C')\n",
    "        axs[j,i].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe')\n",
    "        axs[j,i].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb')\n",
    "        axs[j,i].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='mixed',alpha=0.4)\n",
    "        #axs[j,i].fill(corr_Fe.hmass_x,corr_Fe.hmass_mix,label='Fe (mix)',alpha=0.4)\n",
    "        \n",
    "        axs[j,i].axvline(x=0.770,color='black',alpha=0.6,linestyle='--')\n",
    "        axs[2,i].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text(r'$\\frac{1}{N_{\\mathrm{trigger}}} \\mathrm{d}N_{\\mathrm{pairs}}$',fontsize=18)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Mass_2D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Invariant Mass (z1, z1+z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.5,0.55, 0.65,0.70,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.hmass_x,corr_D.hmass,label='D')\n",
    "            #axs[j,i].fill(corr_C.hmass_x,corr_C.hmass_mix,label='C (mix)',alpha=0.4)\n",
    "            #axs[j,i].fill(corr_Fe.hmass_x,corr_Fe.hmass_mix,label='Fe (mix)',alpha=0.4)\n",
    "\n",
    "            axs[j,i].plot(corr_C.hmass_x,corr_C.hmass,label='C')\n",
    "            axs[j,i].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe')\n",
    "            axs[j,i].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb')\n",
    "            axs[j,i].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='mixed',alpha=0.4)\n",
    "\n",
    "            axs[j,i].axvline(x=0.770,color='black',alpha=0.6,linestyle='--')\n",
    "            axs[3,i].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Mass_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D t distribution vs z1+z2 and z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.5,0.55, 0.65,0.70,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.dipion_pt_x,corr_D.dipion_pt,label='D')\n",
    "            axs[j,i].plot(corr_C.dipion_pt_x,corr_C.dipion_pt,label='C')\n",
    "            axs[j,i].plot(corr_Fe.dipion_pt_x,corr_Fe.dipion_pt,label='Fe')\n",
    "            axs[j,i].plot(corr_Pb.dipion_pt_x,corr_Pb.dipion_pt,label='Pb')\n",
    "\n",
    "#            axs[j,i].axvline(x=0.4,linestyle='--',color='black',alpha=0.6)\n",
    "            axs[3,i].xaxis.set_label_text(\"dipion pT  [GeV]$\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('t_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.15,0.25,0.4]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        axs[j,i].plot(corr_D.dipion_pt_x,corr_D.t,label='D')\n",
    "        axs[j,i].plot(corr_C.dipion_pt_x,corr_C.t,label='C')\n",
    "        axs[j,i].plot(corr_Fe.dipion_pt_x,corr_Fe.t,label='Fe')\n",
    "        axs[j,i].plot(corr_Pb.dipion_pt_x,corr_Pb.t,label='Pb')\n",
    "\n",
    "        plt.xlim([0.0,3.0])\n",
    "\n",
    "        axs[j,i].axvline(x=0.4,linestyle='--',color='black',alpha=0.6)\n",
    "        axs[3,i].xaxis.set_label_text(\"dipion pt [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('dipion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking R2h as a function of z_tot instead of z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pb'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(12,6), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "\n",
    "for target in ['C','Fe','Pb']:\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.55,maxz=1.0,variable='z_tot')\n",
    "    axs[0].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso')\n",
    "    axs[1].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    \n",
    "axs[0].legend()\n",
    "axs[0].xaxis.set_label_text(\"z_2\", fontsize=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results with and without z_tot<0.8 cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(12,6), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "\n",
    "for target in ['C','Fe','Pb']:\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso')\n",
    "    axs[0].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso',pair_cut=' and z_tot<0.8')\n",
    "    axs[1].errorbar(x,r,yerr=err,label=target,fmt='o',mfc='white',ms=8,lw=3,capsize=5)\n",
    "\n",
    "axs[1].set_title('with $z_1+z_2<$0.8', fontsize=13)\n",
    "axs[0].set_title('no cut ', fontsize=13)\n",
    "\n",
    "axs[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the dependency of the ratios on varios things like the charged of leading pion, subleading pion; Q2 and Nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid<0', pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid<0', pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "#plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same sign results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='C, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='Fe, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='Pb, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Varying Nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],query='and Nu>3.2')\n",
    "plt.errorbar(x,r,yerr=err,label='Nu>3.2',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],query='and Nu<3.2')\n",
    "plt.errorbar(x,r,yerr=err,label='Nu<3.2',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],query='and pid*pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='C, Lead, same sign',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],query='and pid*pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='Pb, Lead, same sign',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "plt.show()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z2 distribution breakdown for pi+ and pi- for all nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12, 10))\n",
    "\n",
    "for i, target in enumerate(['D','C','Fe','Pb']):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.hist(df[target].query('z>0.5 and pid_asso>0')['z_asso'], bins=100,range =(0,0.5),label='$\\pi^+$',alpha=0.5)\n",
    "    plt.hist(df[target].query('z>0.5 and pid_asso<0')['z_asso'], bins=100,range =(0,0.5),label='$\\pi^-$',alpha=0.5)\n",
    "\n",
    "    plt.title('%s, Conditional for $z_{1}>0.5$'%target)\n",
    "    plt.ylabel('pairs',fontsize=16)\n",
    "    plt.xlabel('$z_{2}$',fontsize=16)\n",
    "    plt.legend(frameon=False)    \n",
    "\n",
    "plt.savefig('ConditionalDistribution_z2_BothPions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z distribution of triggers by charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12, 10))\n",
    "\n",
    "for i, target in enumerate(['D','C','Fe','Pb']):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.hist(df_trigger['%s_trigger'%target].query('z>0.5 and pid>0')['z'], bins=100,range =(0.5,1.0),label='$\\pi^+$',alpha=0.5)\n",
    "    plt.hist(df_trigger['%s_trigger'%target].query('z>0.5 and pid<0')['z'], bins=100,range =(0.5,1.0),label='$\\pi^-$',alpha=0.5)\n",
    "\n",
    "    plt.ylabel('pairs',fontsize=16)\n",
    "    plt.xlabel('$z_{1}$',fontsize=16)\n",
    "    plt.legend(frameon=False)    \n",
    "\n",
    "plt.savefig('Triggers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Pb'].query('z>0.5 and pid_asso>0')['P_asso'], bins=30,range =(0,1.5),label='pi+',alpha=0.5)\n",
    "plt.hist(df['Pb'].query('z>0.5 and pid_asso<0')['P_asso'], bins=30,range =(0,1.5),label='pi-',alpha=0.5)\n",
    "\n",
    "plt.title('Conditional distribution for $z_{1}>0.5$',fontsize=16)\n",
    "plt.ylabel('pairs',fontsize=16)\n",
    "plt.xlabel('$P_{2}$',fontsize=16)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('ConditionalDistributionMomentum_Deuterium.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
