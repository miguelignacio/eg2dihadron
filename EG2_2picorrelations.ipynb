{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pandas as pd \n",
    "import time\n",
    "import root_pandas as rpd\n",
    "from root_pandas import read_root\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 6.2,3.5\n",
    "mpl.rcParams['axes.labelsize'] = 17\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['lines.markersize'] = 6\n",
    "mpl.rcParams['legend.fontsize']= 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class correlation:\n",
    "    def __init__(self, ntriggers, df, df_mixed):\n",
    "        \n",
    "        self.nbins_dphi = 6#32\n",
    "        self.nbins_deta = 18#16\n",
    "        self.ntriggers = ntriggers\n",
    "        self.phibins = np.linspace(0, np.pi, self.nbins_dphi+1)#16+1) #was 16+1\n",
    "        #        self.phibins = np.linspace(-np.pi, np.pi, self.nbins_dphi+1)#16+1) #was 16+1\n",
    "        #self.etabins = np.linspace(-np.pi, np.pi, self.nbins_deta+1)#16+1) #was 16+1\n",
    "        self.etabins = np.linspace(-0.5, 4, self.nbins_deta+1) #was 16+1        \n",
    "        \n",
    "        \n",
    "        self.bincenters_dphi = [np.mean([x, y]) for (x, y) in zip(self.phibins[:-1], self.phibins[1:])]\n",
    "        self.bincenters_deta = [np.mean([x, y]) for (x, y) in zip(self.etabins[:-1], self.etabins[1:])]\n",
    "        \n",
    "        dphi = list(df['dphi'])\n",
    "        dphi_lab = list(df['dphi_lab'])\n",
    "        deta = list(df['dy'])\n",
    "        mixed_dphi = list(df_mixed['dphi'])\n",
    "        mixed_dphi_lab = list(df_mixed['dphi_lab'])\n",
    "        mixed_deta = list(df_mixed['dy'])\n",
    "        \n",
    "        self.numberofpairs = df.shape[0]\n",
    "        \n",
    "        #1D correlations\n",
    "        #dphi\n",
    "        self.sameh_dphi =myHisto(dphi, self.phibins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_dphi.norm(ntriggers)   \n",
    "        self.mixh_dphi  =myHisto(mixed_dphi, self.phibins)\n",
    "        norm = sum(self.mixh_dphi.y)#/self.nbins_dphi\n",
    "        self.mixh_dphi.norm(norm)\n",
    "        self.corr_dphi = np.true_divide(self.sameh_dphi.y,self.mixh_dphi.y)\n",
    "        self.corr_dphi_err = np.true_divide(self.sameh_dphi.yerr,self.mixh_dphi.y)\n",
    "\n",
    "        #dphi in lab frame\n",
    "        self.sameh_dphi_lab =myHisto(dphi_lab, self.phibins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_dphi_lab.norm(ntriggers)   \n",
    "        self.mixh_dphi_lab  =myHisto(mixed_dphi_lab, self.phibins)\n",
    "        norm = sum(self.mixh_dphi_lab.y)/self.nbins_dphi\n",
    "        self.mixh_dphi_lab.norm(norm)\n",
    "        self.corr_dphi_lab = np.true_divide(self.sameh_dphi_lab.y,self.mixh_dphi_lab.y)\n",
    "        self.corr_dphi_lab_err = np.true_divide(self.sameh_dphi_lab.yerr,self.mixh_dphi_lab.y)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.sameh_deta =myHisto(deta, self.etabins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_deta.norm(ntriggers)\n",
    "        self.mixh_deta  =myHisto(mixed_deta, self.etabins)\n",
    "        norm = sum(self.mixh_deta.y)/self.nbins_deta #sum(self.mixh_deta.y)/self.nbins_deta\n",
    "        self.mixh_deta.norm(norm)\n",
    "        #self.corr_deta     = np.true_divide(self.sameh_deta.y,self.mixh_deta.y)\n",
    "        #self.corr_deta_err = np.true_divide(self.sameh_deta.yerr,self.mixh_deta.y)\n",
    "\n",
    "        # 2D correlations\n",
    "        \n",
    "        #self.sameh_2d, self.xedges,self.yedges = np.histogram2d(deta,dphi, [self.etabins,self.phibins])\n",
    "        #self.mixh_2d, self.xedges,self.yedges = np.histogram2d(mixed_deta,mixed_dphi, [self.etabins,self.phibins])\n",
    "\n",
    "        #get correlation function\n",
    "        #self.corr_2d = np.true_divide(self.sameh_2d,self.mixh_2d)\n",
    "        #self.extent = [self.xedges[0], self.xedges[-1], self.yedges[0], self.yedges[-1]]\n",
    "        \n",
    "        #MASS: \n",
    "        self.hmass, self.hmass_x = np.histogram(df['mass'],range=(0.0,2.0),density=True, bins=50)\n",
    "        self.hmass_mix, self.hmass_x = np.histogram(df_mixed['mass'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.hmass_x = (self.hmass_x[1:] + self.hmass_x[:-1])/2.0\n",
    "        \n",
    "        self.hxmass, self.hxmass_x = np.histogram(df['missing_mass'],range=(0.0,2.0),density= True, bins=50)\n",
    "        self.hxmass_mix, self.hxmass_x = np.histogram(df_mixed['missing_mass'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.hxmass_x = (self.hxmass_x[1:] + self.hxmass_x[:-1])/2.0\n",
    "        \n",
    "        #self.t, self.t_x = np.histogram(df['t'],range=(0.0,5.0), density= True, bins=50)\n",
    "        #self.t_mix, self.t_x = np.histogram(df_mixed['t'],range=(0.0,5.0),density=True,bins=50)\n",
    "        #self.t_x = (self.t_x[1:] + self.t_x[:-1])/2.0\n",
    "        \n",
    "        self.dipion_pt, self.dipion_pt_x = np.histogram(df['dipion_pt'],range=(0.0,2.0), density = True, bins=50)\n",
    "        self.dipion_pt_mix, self.dipion_pt_x = np.histogram(df_mixed['dipion_pt'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.dipion_pt_x = (self.dipion_pt_x[1:] + self.dipion_pt_x[:-1])/2.0\n",
    "        \n",
    "\n",
    "    def normalize(self,norma):\n",
    "        #print 'sum entrifes beforoe normalization' ,np.sum(self.corr_dphi)\n",
    "        #print 'requested normalization' , norma\n",
    "        self.corr_dphi     = np.true_divide(self.corr_dphi, norma)\n",
    "        #print ' sum entries after normalization', np.sum(self.corr_dphi)\n",
    "        self.corr_dphi_err = np.true_divide(self.corr_dphi_err,norma)\n",
    "        \n",
    "        self.sameh_dphi_lab.y = np.true_divide(self.sameh_dphi_lab.y,norma)\n",
    "        self.sameh_dphi.y = np.true_divide(self.sameh_dphi.y,norma)\n",
    "        self.sameh_dphi_lab.yerr = np.true_divide(self.sameh_dphi_lab.yerr,norma)\n",
    "        self.sameh_dphi.yerr = np.true_divide(self.sameh_dphi.yerr,norma)\n",
    "        \n",
    "        \n",
    "        return \n",
    "\n",
    "class comparison:\n",
    "    def __init__(self, corr_A, corr_D):\n",
    "        \n",
    "        self.corr_A = corr_A.corr_dphi\n",
    "        self.corr_D = corr_D.corr_dphi\n",
    "        self.err_A  = corr_A.corr_dphi_err\n",
    "        self.err_D  = corr_D.corr_dphi_err\n",
    "        self.dif_err = np.sqrt(np.power(self.err_A,2.0)+np.power(self.err_D,2.0)) #error for difference\n",
    "        self.diff  = np.subtract(self.corr_A,self.corr_D)\n",
    "        self.ratio = np.true_divide(self.corr_A,self.corr_D)\n",
    "        self.ratio_err = np.sqrt(np.power(np.divide(self.err_A,self.corr_A),2.0)+np.power(np.divide(self.err_D,self.corr_D),2.0))*self.ratio \n",
    "        \n",
    "       \n",
    "        \n",
    "class myHisto:\n",
    "    def __init__(self, data, bins):\n",
    "        self.bins = bins\n",
    "        self.y    = np.histogram(data, self.bins)[0]\n",
    "        self.yerr = np.sqrt(self.y)\n",
    "    def norm(self, norm=1.0):\n",
    "        self.y = np.true_divide(self.y, norm)\n",
    "        self.yerr = np.true_divide(self.yerr, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRatio(df_A,df_D,df_trigger_A,df_trigger_D, variable='z_asso',trig_cut = 'z>0.5', pair_cut='',minz=0.08,maxz=0.45,nbins=9, applyweight=False):\n",
    "    #get number of pions with z>0.5\n",
    "    print ('Print Trigger Cut ' ,trig_cut)\n",
    "    print ('Total Cut ', trig_cut + pair_cut)\n",
    "    \n",
    "    norm_A = df_trigger_A.query(trig_cut).shape[0]\n",
    "    norm_D = df_trigger_D.query(trig_cut).shape[0]\n",
    "    \n",
    "    #norm_A , xx = np.histogram( df_trigger_A.query(trig_cut),bins=np.array([0.5,1.0]))\n",
    "    \n",
    "    if(applyweight):\n",
    "        y_A, x_conditional = np.histogram(df_A.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins),weights=df_A.query(trig_cut+pair_cut)['weight'])\n",
    "        y_D, x_conditional = np.histogram(df_D.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins),weights=df_D.query(trig_cut+pair_cut)['weight'])\n",
    "        erry_A, x_conditional = np.histogram(df_A.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins),weights=df_A.query(trig_cut+pair_cut)['weight2'])\n",
    "        erry_D, x_conditional = np.histogram(df_D.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins),weights=df_D.query(trig_cut+pair_cut)['weight2'])\n",
    "    \n",
    "    else:\n",
    "        y_A, x_conditional = np.histogram(df_A.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "        y_D, x_conditional = np.histogram(df_D.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "        erry_A, x_conditional = np.histogram(df_A.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "        erry_D, x_conditional = np.histogram(df_D.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "  \n",
    "    x_conditional = (x_conditional[1:] + x_conditional[:-1])/2.0\n",
    "    err_A = np.true_divide(np.sqrt(erry_A),y_A)\n",
    "    err_D = np.true_divide(np.sqrt(erry_D),y_D)\n",
    "    y_A = np.true_divide(y_A,norm_A)\n",
    "    y_D = np.true_divide(y_D,norm_D)\n",
    "    ratio_conditional = np.true_divide(y_A,y_D)\n",
    "    error_conditional = np.multiply(ratio_conditional, np.sqrt(np.power(err_A,2.0) + np.power(err_D,2.0)))\n",
    "    \n",
    "    return ratio_conditional,error_conditional,x_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAcceptance(momentum=1.0,theta=20.0, pid=211, targtype='solid'):\n",
    "    x = np.array([0.0325, 0.0975 , 0.1625 , 0.2275 , 0.2925 , 0.3575 , 0.4225 , 0.4875 , 0.5525 , 0.6175 , 0.6825 , 0.7475 , 0.8125 , 0.8775 , 0.9425 , 1.0075 , 1.0725 , 1.1375 , 1.2025 , 1.2675  ])  \n",
    "    solidtarget_pim = {}\n",
    "    liquidtarget_pim = {}\n",
    "    \n",
    "        \n",
    "    solidtarget_pim['1'] = np.array([0,0 ,0 ,0 ,0 ,3.23167e-06 ,0.001560151 , 0.01057529,0.01825397 ,0.0261568 , 0.03116873,0.03466488 , 0.03863429,0.04103578 , 0.04319868,0.04477068 ,0.0459576 ,0.04610074 ,0.04597379 ,0.041296720])\n",
    "    liquidtarget_pim['1'] = np.array([ 0 ,0 ,0 ,0 ,0 ,1.61536e-06 ,0.002657303 ,0.01237076 , 0.02036797,0.02867371 ,0.03345114 ,0.0380118 , 0.04140325, 0.04386796, 0.04682532,0.04792033 ,0.04949423 ,0.04856436 ,0.04892293 ,0.04327102 ])\n",
    "\n",
    "    solidtarget_pim['2'] = np.array([ 0 ,0 ,0.002629189 ,0.03186881 ,0.06729287 ,0.1043241 , 0.1307755, 0.1355177, 0.1339914, 0.1398696,0.1373173 ,0.1340744 ,0.1331808 , 0.130854, 0.1272746, 0.1236089,0.1165032 ,0.1128401 ,0.1072237 ,0.09178725  ])\n",
    "    liquidtarget_pim['2'] = np.array([0. ,0. ,0.002954789 ,0.03605334 ,0.07328045 ,0.1112898 ,0.1340548 ,0.1370217 ,0.1376773 ,0.1419643 ,0.1419834 ,0.1377389 ,0.1373697 ,0.1353414 ,0.132038 ,0.1265082 ,0.1199043 ,0.1178251 ,0.1116354 ,0.09549689  ])\n",
    "\n",
    "    solidtarget_pim['3'] = np.array([ 0.0002231072 ,0.1211735 ,0.2128658 ,0.2396404 ,0.2553216 ,0.2658868 ,0.2700335 ,0.2717077 ,0.2731176 ,0.2821284 ,0.2848298 ,0.2837925 ,0.2846656 ,0.2829416 ,0.2791555 ,0.2721919 ,0.2692559 ,0.2690514 ,0.2679086 ,0.2478978 ])\n",
    "    liquidtarget_pim['3'] = np.array([ 0.00660692 ,0.1578462 ,0.2173256 ,0.2422208 ,0.257946 ,0.2675358 ,0.2723963 ,0.2755941 ,0.2744294 ,0.2831314 ,0.2860147 ,0.2841786 ,0.2849058 ,0.2853593 ,0.2794619 ,0.2754566 ,0.2712428 ,0.2708606 ,0.2692244 ,0.2487378 ])\n",
    "\n",
    "    solidtarget_pim['4'] = np.array([ 0.001333508,0.1449459 ,0.2186205 ,0.2415341 ,0.2531107 ,0.2574371 ,0.2609193 ,0.2617711 ,0.262772 ,0.2752933 ,0.2799949 ,0.2802792 ,0.281052 ,0.2796929 ,0.2742227 ,0.2711661 ,0.2740372 ,0.2708804 ,0.2731924 ,0.2612534 ])\n",
    "    liquidtarget_pim['4'] = np.array([ 0.02327899 ,0.1629743 ,0.2106435 ,0.2306853 ,0.2454332 ,0.2509662 ,0.2547484 ,0.256513 ,0.2575279 ,0.2676785 ,0.2702532 ,0.2706461 ,0.2732721 ,0.2716608 ,0.2654282 ,0.2629694 ,0.2660801 ,0.263469 ,0.2604181 ,0.2622458 ])\n",
    "\n",
    "    solidtarget_pim['5'] = np.array([0.006982775 ,0.1447486 ,0.1897953 ,0.2084306 ,0.2172206 ,0.2223349 ,0.2240443 ,0.2250739 ,0.2231615 ,0.2327872 ,0.2361698 ,0.2290048,0.231793 ,0.2323416 ,0.2202763 ,0.2219534 ,0.2157027 ,0.2203591 ,0.2019774 ,0.1933508 ])\n",
    "    liquidtarget_pim['5'] = np.array([0.03545699 ,0.1620397 ,0.1961021 ,0.2146192 ,0.2243374,0.2282763 ,0.2288964 ,0.2295778 ,0.2266956 ,0.2375714 ,0.2389445 ,0.2341746 ,0.2357495 ,0.2359444 ,0.224392 ,0.2227679 ,0.2211828 ,0.2209665 ,0.2165821 ,0.1870061 ])\n",
    "\n",
    "    solidtarget_pim['6'] = np.array([0.009253875 ,0.1392653 ,0.1971637 ,0.2154679 ,0.2187641 ,0.225096,0.2284017 ,0.2305547 ,0.2317961 ,0.2408562 ,0.2482083 ,0.2436806 ,0.2344238 ,0.2462491 ,0.2138468 ,0.2307692 ,0.2372414 ,0.2157895 ,0.2 ,0. ])\n",
    "    liquidtarget_pim['6'] = np.array([ 0.02504874 ,0.1437731 ,0.1910572 ,0.2113901 ,0.2182047 ,0.2246697 ,0.2270944 ,0.231018 ,0.2354003 ,0.2440679 ,0.2582594 ,0.2499597 ,0.2501701 ,0.2524341 ,0.2451745 ,0.2437037 ,0.2410468 ,0.2362205 ,0.16 ,0. ])\n",
    "\n",
    "    solidtarget_pim['7'] = np.array([ 6.89698e-06 ,0.01220896 ,0.03071677 ,0.03531329 ,0.04548552 ,0.06199558 ,0.09144737 ,0.1081081,0.2222222 ,3 ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ])\n",
    "    liquidtarget_pim['7'] = np.array([ 2.068238e-05 ,0.01000872 ,0.02016303 ,0.02335588 ,0.03246062 ,0.04609146 ,0.07527773 ,0.1166181 ,0.2666667 ,3.666667 ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ])\n",
    "\n",
    "    \n",
    "    solidtarget_pip = {}\n",
    "    liquidtarget_pip = {}\n",
    "    \n",
    "    #//pi+\n",
    "    solidtarget_pip['1'] = np.array([ 0. ,0.0263211 ,0.1196485 ,0.1645991 ,0.1794361 ,0.207905 ,0.2125451 ,0.2075122 ,0.2127852 ,0.2212154 ,0.2248536 ,0.226564 ,0.2281049 ,0.2298948 ,0.2274279 ,0.2259013 ,0.2228642 ,0.223829 ,0.2221386 ,0.1908589 ])\n",
    "    liquidtarget_pip['1'] = np.array([0. ,0.03226664 ,0.1235518 ,0.1673732 ,0.1845819 ,0.2111029 ,0.2143435 ,0.2117669 ,0.2165755 ,0.2239562 ,0.2277253 ,0.2289291 ,0.2305655 ,0.2331748 ,0.2294087 ,0.2276427 ,0.2249865 ,0.2261938 ,0.2235695 ,0.1942732 ])\n",
    "\n",
    "    solidtarget_pip['2'] = np.array([1.746534e-05 ,0.07758519 ,0.1789028 ,0.2142687 ,0.2309015 ,0.230986 ,0.231743,0.2343798 ,0.2348231 ,0.2442682 ,0.246481 ,0.2453539 ,0.2416622 ,0.2401279 ,0.2368902 ,0.2353596 ,0.2374409 ,0.2360786 ,0.2338877 ,0.221718 ])\n",
    "    liquidtarget_pip['2'] = np.array([ 4.36685e-05,0.1020439 ,0.1824278 ,0.2151706 ,0.2314508 ,0.2324465 ,0.2368424 ,0.2384085 ,0.2403754 ,0.249458 ,0.2504815 ,0.247795 ,0.2451 ,0.2430814 ,0.2397604 ,0.2377985 ,0.2396885 ,0.2378236 ,0.2350796 ,0.2228359 ])\n",
    "\n",
    "    solidtarget_pip['3'] = np.array([ 0.0002231072 ,0.1211735 ,0.2128658 ,0.2396404 ,0.2553216 ,0.2658868 ,0.2700335 ,0.2717077 ,0.2731176 ,0.2821284 ,0.2848298 ,0.2837925 ,0.2846656 ,0.2829416 ,0.2791555 ,0.2721919 ,0.2692559 ,0.2690514 ,0.2679086 ,0.2478978 ])\n",
    "    liquidtarget_pip['3'] = np.array([ 0.00660692 ,0.1578462 ,0.2173256 ,0.2422208 ,0.257946 ,0.2675358 ,0.2723963 ,0.2755941 ,0.2744294 ,0.2831314 ,0.2860147 ,0.2841786 ,0.2849058 ,0.2853593 ,0.2794619 ,0.2754566 ,0.2712428 ,0.2708606 ,0.2692244 ,0.2487378 ])\n",
    "\n",
    "    solidtarget_pip['4'] = np.array([0.001333508,0.1449459 ,0.2186205 ,0.2415341 ,0.2531107 ,0.2574371 ,0.2609193 ,0.2617711 ,0.262772 ,0.2752933 ,0.2799949 ,0.2802792 ,0.281052 ,0.2796929 ,0.2742227 ,0.2711661 ,0.2740372 ,0.2708804 ,0.2731924 ,0.2612534 ])\n",
    "    liquidtarget_pip['4'] = np.array([  0.02327899 ,0.1629743 ,0.2106435 ,0.2306853 ,0.2454332 ,0.2509662 ,0.2547484 ,0.256513 ,0.2575279 ,0.2676785 ,0.2702532 ,0.2706461 ,0.2732721 ,0.2716608 ,0.2654282 ,0.2629694 ,0.2660801 ,0.263469 ,0.2604181 ,0.2622458 ])\n",
    "\n",
    "    solidtarget_pip['5'] = np.array([ 0.006982775 ,0.1447486 ,0.1897953 ,0.2084306 ,0.2172206 ,0.2223349 ,0.2240443 ,0.2250739 ,0.2231615 ,0.2327872 ,0.2361698 ,0.2290048,0.231793 ,0.2323416 ,0.2202763 ,0.2219534 ,0.2157027 ,0.2203591 ,0.2019774 ,0.1933508 ])\n",
    "    liquidtarget_pip['5'] = np.array([ 0.03545699 ,0.1620397 ,0.1961021 ,0.2146192 ,0.2243374,0.2282763 ,0.2288964 ,0.2295778 ,0.2266956 ,0.2375714 ,0.2389445 ,0.2341746 ,0.2357495 ,0.2359444 ,0.224392 ,0.2227679 ,0.2211828 ,0.2209665 ,0.2165821 ,0.1870061 ])\n",
    "\n",
    "    solidtarget_pip['6'] = np.array([0.009253875 ,0.1392653 ,0.1971637 ,0.2154679 ,0.2187641 ,0.225096,0.2284017 ,0.2305547 ,0.2317961 ,0.2408562 ,0.2482083 ,0.2436806 ,0.2344238 ,0.2462491 ,0.2138468 ,0.2307692 ,0.2372414 ,0.2157895 ,0.2 ,0. ])\n",
    "    liquidtarget_pip['6'] = np.array([ 0.02504874 ,0.1437731 ,0.1910572 ,0.2113901 ,0.2182047 ,0.2246697 ,0.2270944 ,0.231018 ,0.2354003 ,0.2440679 ,0.2582594 ,0.2499597 ,0.2501701 ,0.2524341 ,0.2451745 ,0.2437037 ,0.2410468 ,0.2362205 ,0.16 ,0. ])\n",
    "\n",
    "    solidtarget_pip['7'] = np.array([ 6.89698e-06 ,0.01220896 ,0.03071677 ,0.03531329 ,0.04548552 ,0.06199558 ,0.09144737 ,0.1081081,0.2222222 ,3 ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ]);\n",
    "    liquidtarget_pip['7'] = np.array([2.068238e-05 ,0.01000872 ,0.02016303 ,0.02335588 ,0.03246062 ,0.04609146 ,0.07527773 ,0.1166181 ,0.2666667 ,3.666667 ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ,0. ]);\n",
    "\n",
    "\n",
    "    bin_number = None\n",
    "    #print (theta)\n",
    "    if(10 <theta<=30):\n",
    "        bin_number = '1'\n",
    "    elif(30<theta<=45):\n",
    "        bin_number = '2'\n",
    "    elif(45<theta<=60):\n",
    "        bin_number = '3'\n",
    "    elif(60<theta<=75):\n",
    "        bin_number = '4'   \n",
    "    elif(75<theta<=90):\n",
    "        bin_number = '5'   \n",
    "    elif(90<theta<=120):\n",
    "        bin_number = '6'   \n",
    "    elif(120<theta<=145):\n",
    "        bin_number = '7' \n",
    "    else:\n",
    "        print ('No valid theta value was passed=%2.2f'%theta)\n",
    "    \n",
    "    #print (bin_number)\n",
    "    acc = 1.00\n",
    "    \n",
    "    idx = (np.abs(x-momentum)).argmin()\n",
    "    #print (idx)\n",
    "    \n",
    "    \n",
    "    if bin_number==None:\n",
    "        acc = 1.0\n",
    "    elif(targtype=='solid' and pid==-211):\n",
    "        acc = solidtarget_pim[bin_number][idx]\n",
    "    elif(targtype=='liquid' and pid==-211):\n",
    "        acc = liquidtarget_pim[bin_number][idx]\n",
    "    elif(targtype=='solid' and pid==211):\n",
    "        acc = solidtarget_pip[bin_number][idx]\n",
    "    elif(targtype=='liquid' and pid==211):\n",
    "        acc = liquidtarget_pip[bin_number][idx]\n",
    "    else:\n",
    "        acc = 1.0\n",
    "    #return momentum\n",
    "    \n",
    "    \n",
    "    if(acc>0.0):\n",
    "        weight = 1.0/acc\n",
    "    else:\n",
    "        weight = 1.0\n",
    "        print('weight invalid')\n",
    "        \n",
    "    return weight\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCut(inputDataframe, cut, text=None):\n",
    "    nbeforecut = inputDataframe.shape[0]\n",
    "    cutDataframe = None\n",
    "    if nbeforecut>0:\n",
    "        cutDataframe = inputDataframe.query(cut)\n",
    "        if text:\n",
    "            print (text, cutDataframe.shape[0], ' (%2.2f '%(100.0*cutDataframe.shape[0]/nbeforecut), '%)')\n",
    "    return cutDataframe\n",
    "def applyCuts(fullDataframe,name='default',isMC=False,isTrigger=True): \n",
    "    dataframe = fullDataframe\n",
    "    print ('Entries before cut ', dataframe.shape[0])\n",
    "    dataframe.eval('inelasticity = nu/5.014', inplace=True)\n",
    "    if isTrigger:\n",
    "        dataframe.eval('h1_z = h_z', inplace=True)\n",
    "\n",
    "    dataframe.eval('h1_e = h1_z*nu', inplace=True)\n",
    "    dataframe.eval('h1_p = sqrt(h1_e*h1_e-0.138*0.138)', inplace=True)\n",
    "    \n",
    "    dataframe = applyCut(dataframe, 'Q2>1.0', 'Q2>1.0 :')\n",
    "    #dataframe = applyCut(dataframe, 'Nu>3.0 and Nu<3.5', '3.0 < Nu < 3.5')\n",
    "    #dataframe = applyCut(dataframe, 'h_z>0.5', 'h_z>0.5 :')\n",
    "    dataframe = applyCut(dataframe, 'h1_p <2.5 ', 'h1_p<2.5 ')\n",
    "\n",
    "    dataframe = applyCut(dataframe, 'inelasticity<0.85','inelasticity < 0.85')\n",
    "    return dataframe\n",
    "\n",
    "def applyCutsPair(fullDataframe,name='default',isMC=False):\n",
    "    print ('Starting election on dipion variables')\n",
    "    if (isMC):\n",
    "        print ('This is MC')\n",
    "    else: \n",
    "        print ('This is Data')\n",
    "    \n",
    "    dataframe = fullDataframe\n",
    "    dataframe.eval('z_tot = h1_z+ h2_z', inplace=True)\n",
    "    dataframe.eval('h1_e = h1_z*nu', inplace=True)\n",
    "    dataframe.eval('h1_p = sqrt(h1_e*h1_e-0.138*0.138)', inplace=True)\n",
    "    dataframe.eval('h2_e = h2_z*nu', inplace=True)\n",
    "    dataframe.eval('h2_p = sqrt(h2_e*h2_e-0.138*0.138)', inplace=True)\n",
    "    dataframe = applyCut(dataframe, 'Q2>1.0', 'Q2>1.0 :')\n",
    "    #dataframe = applyCut(dataframe, 'nu>3.0 and nu<3.5', '3.0 < nu < 3.5')\n",
    "    dataframe = applyCut(dataframe, 'h1_z>0.5', 'h1_z>0.5 :')\n",
    "    dataframe = applyCut(dataframe, 'h1_p <2.5 ', 'h1_p<2.5 ')\n",
    "\n",
    "    dataframe = applyCut(dataframe, 'h1_pid*h2_pid<0', 'Opposite sign pairs')\n",
    "    dataframe.eval('pair_pt2 = pair_pt*pair_pt', inplace=True)\n",
    "\n",
    "    ##Polar angle acceptance, different for \n",
    "    #if(isMC==False):\n",
    "    #    print 'Polar angle acceptance'\n",
    "    #    dataframe = applyCut(dataframe,'(pid_asso==211 & theta_lab_asso>10 & theta_lab_asso<90)|(pid_asso==-211 & theta_lab_asso>45 & theta_lab_asso<90)')\n",
    "    if (not isMC):\n",
    "        \n",
    "        dataframe = applyCut(dataframe, 'h2_th<120 and h2_th>10', '10< h2_th<120')\n",
    "        dataframe = applyCut(dataframe, 'h2_p>0.200', 'h2_p>0.200')\n",
    "        dataframe = applyCut(dataframe,'(h2_pid==211)| (h2_pid==-211 & h2_th>30)| (h2_pid==-211 & h2_th<30 & h2_p>0.600)','P>500 for pi- with theta<30')\n",
    "\n",
    "        #dataframe = applyCut(dataframe,'(pid_asso==211 & theta_lab_asso>10.0)|(pid_asso==-211 & theta_lab_asso>30 & theta_lab_asso<120)')\n",
    "    dataframe = applyCut(dataframe, 'h2_p<2.5', 'h2_p <2.5 GeV')\n",
    "    #dataframe = applyCut(dataframe, 'mass<2.0', 'mass < 2.0 GeV')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def printPairBreakdown(dataframe):\n",
    "    allpairs = 1.0*dataframe.shape[0]\n",
    "    print ('All pairs ', allpairs)\n",
    "    print ('Pairs with Leading pi+', np.true_divide(dataframe.query('pid==211').shape[0],allpairs))\n",
    "    print ('Pairs with Leading pi-', dataframe.query('pid==-211').shape[0]/allpairs)\n",
    "    print ('Pairs with Sub-Leading pi+', dataframe.query('pid_asso==211').shape[0]/allpairs)\n",
    "    print ('Pairs with Sub-Leading pi-', dataframe.query('pid_asso==-211').shape[0]/allpairs)\n",
    "    print ('pi+ pi+ pairs',dataframe.query('pid==211 and pid_asso==211').shape[0]/allpairs)\n",
    "    print ('pi- pi- pairs',dataframe.query('pid==-211 and pid_asso==-211').shape[0]/allpairs)\n",
    "    print ('pi+ pi- pairs',dataframe.query('pid==211 and pid_asso==-211').shape[0]/allpairs)\n",
    "    print ('pi- pi+ pairs',dataframe.query('pid==-211 and pid_asso==211').shape[0]/allpairs)\n",
    "    print ('//////////////////////////////////////////////////////')\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from Ntuples to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this needs to be read in chunks otherwise it uses all memory. (from https://github.com/scikit-hep/root_pandas)\n",
    "def getdatainChunks(filename,treename):\n",
    "    dataframe =pd.DataFrame()\n",
    "    for df in read_root(filename, treename, chunksize=100000) :\n",
    "        #print df.shape[0]\n",
    "        dataframe = pd.concat([dataframe,df])\n",
    "    \n",
    "    print (dataframe.shape[0])\n",
    "    return dataframe\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataframes from target C\n",
      "235958\n",
      "538211\n",
      "326770\n",
      "739940\n",
      "Get trigger dataframes from targetC\n",
      "979565\n",
      "1308621\n",
      "Getting dataframes from target Fe\n",
      "186543\n",
      "406467\n",
      "351312\n",
      "797957\n",
      "Get trigger dataframes from targetFe\n",
      "840718\n",
      "1412003\n"
     ]
    }
   ],
   "source": [
    "df = {}\n",
    "df_trigger = {}\n",
    "\n",
    "for target in ['C','Fe']:\n",
    "    print ('Getting dataframes from target %s'%target)\n",
    "    df[target]=getdatainChunks('Pairs_%s.root'%target, target)\n",
    "    df['%s_mix'%target] = getdatainChunks('Pairs_%s.root'%target, '%s_mix'%target)\n",
    "    df['D_%s'%target]= getdatainChunks('Pairs_%s.root'%target, 'D_%s'%target)\n",
    "    df['D_%s_mix'%target] = getdatainChunks('Pairs_%s.root'%target, 'D_%s_mix'%target)\n",
    "    \n",
    "    print ('Get trigger dataframes from target%s'%target)\n",
    "    df_trigger['%s_trigger'%target] = getdatainChunks('Pairs_%s.root'%target, '%s_trigger'%target)\n",
    "    df_trigger['D_%s_trigger'%target] = getdatainChunks('Pairs_%s.root'%target, 'D_%s_trigger'%target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GiBUU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['D','C','Fe','Pb']:#,'Fe','C']:\n",
    "    #GiBUU\n",
    "    print (target)\n",
    "    print ('----pairs')\n",
    "    df['GiBUU_%s'%target]= getdatainChunks('GiBUU_Pairs_%s.root'%target, target)\n",
    "    print ('----trigger')\n",
    "    df_trigger['GiBUU_%s_trigger'%target]= getdatainChunks('GiBUU_Pairs_%s.root'%target, '%s_trigger'%target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the deuterium datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D'] = pd.concat([df['D_Pb'],df['D_Fe'],df['D_C']]) #simply combine the deuterium results for all targets\n",
    "df['D_mix'] = pd.concat([df['D_Pb_mix'],df['D_Fe_mix'],df['D_C_mix']]) #simply combine the deuterium results for all targets\n",
    "df_trigger['D_trigger'] = pd.concat([df_trigger['D_Pb_trigger'],df_trigger['D_Fe_trigger'],df_trigger['D_C_trigger']]) #simply combine the deuterium results for all targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#dataframees with pairs\n",
    "for key in df.keys():\n",
    "    isMC = False\n",
    "    if 'GiBUU' in key:\n",
    "        isMC=True\n",
    "    print (key)\n",
    "    \n",
    "    df[key] = applyCuts(df[key],isMC=isMC)\n",
    "    #printPairBreakdown(df[key])\n",
    "    df[key] = applyCutsPair(df[key],isMC=isMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply cuts for trigger dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_trigger.keys():\n",
    "    print (key)\n",
    "    df_trigger[key] = applyCuts(df_trigger[key])\n",
    "    print (' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['C','Fe','Pb']:\n",
    "    df['%s'%target]['weight'] = df['%s'%target].apply(lambda x: getAcceptance(x['P_asso'], x['theta_lab_asso'],x['pid_asso'],'solid'), axis=1)\n",
    "    df['D_%s'%target]['weight'] = df['D_%s'%target].apply(lambda x: getAcceptance(x['P_asso'], x['theta_lab_asso'],x['pid_asso'],'liquid'), axis=1)\n",
    "    \n",
    "    df['%s'%target]['weight2'] = df['%s'%target]['weight'].apply(lambda x: x*x)  \n",
    "    df['D_%s'%target]['weight2'] = df['D_%s'%target]['weight'].apply(lambda x: x*x)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Mixing corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(14,8))\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.3,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print (query_total)\n",
    "    print (df_trigger['Pb_trigger'].query(query_trigger).shape[0])\n",
    "    corr = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    \n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi.y, yerr=corr_D.sameh_dphi.yerr, linewidth=3.0,alpha=0.7,fmt='-o', label='Uncorrected')\n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.corr_dphi, yerr=corr_D.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Corrected')\n",
    "\n",
    "    axs[0,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=15)\n",
    "    axs[0,j].legend(loc='best',frameon=False)\n",
    "    axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=16)\n",
    "    axs[0,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "    axs[1,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[1,j].errorbar(corr_D.bincenters_dphi, corr_D.mixh_dphi.y, yerr=corr_D.mixh_dphi.yerr, linewidth=3.0,alpha=0.7,fmt='-ko', label='Mixed Events')\n",
    "    axs[1,0].yaxis.set_label_text('norm units',fontsize=16)\n",
    "    axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=15)\n",
    "    axs[1,j].legend(loc='best',frameon=False)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('EventMixing_AzimuthalCorrelations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event mixing corrections for lab frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4,figsize=(14,8))\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.3,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print (query_total)\n",
    "    print (df_trigger['Pb_trigger'].query(query_trigger).shape[0])\n",
    "    corr = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    \n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi_lab.y, yerr=corr_D.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o', label='Uncorrected')\n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.corr_dphi_lab, yerr=corr_D.corr_dphi_lab_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Corrected')\n",
    "\n",
    "    axs[0,j].xaxis.set_label_text(\"|$\\Delta\\phi_{lab}$|  [rad]\", fontsize=15)\n",
    "    axs[0,j].legend(loc='best',frameon=False)\n",
    "    axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{lab})/M(z_{1}>0.5)$',fontsize=16)\n",
    "    axs[0,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "    axs[1,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[1,j].errorbar(corr_D.bincenters_dphi, corr_D.mixh_dphi_lab.y, yerr=corr_D.mixh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-ko', label='Mixed Events')\n",
    "    axs[1,0].yaxis.set_label_text('norm units',fontsize=16)\n",
    "    axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{lab}$|  [rad]\", fontsize=15)\n",
    "    axs[1,j].legend(loc='best',frameon=False)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('EventMixing_AzimuthalCorrelations_LabFrame.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azimuthal correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3,sharex=True,sharey='row', figsize=(12,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "#asso_Edges = [0.06,0.1, 0.15,0.25,0.5]\n",
    "asso_Edges = [0.1,0.15,0.25,0.5]#,0.3,0.5]\n",
    "\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print (query_total)\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    ##Combined deuterium for plotting purposes\n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "    \n",
    "    #plots:\n",
    "    #correlations\n",
    "    \n",
    "\n",
    "    axs[0,j].errorbar(np.subtract(corr_D.bincenters_dphi,0.0), corr_D.corr_dphi, yerr=corr_D.corr_dphi_err, linewidth=1.0,fmt='ko', label='D')\n",
    "    axs[0,j].errorbar(np.subtract(corr_C.bincenters_dphi,-0.05), corr_C.corr_dphi, yerr=corr_C.corr_dphi_err, linewidth=1.0,fmt='o', label='C')\n",
    "    axs[0,j].errorbar(np.subtract(corr_Fe.bincenters_dphi,-0.10), corr_Fe.corr_dphi, yerr=corr_Fe.corr_dphi_err, linewidth=1.0,fmt='o', label='Fe')\n",
    "    axs[0,j].errorbar(np.subtract(corr_Pb.bincenters_dphi,-0.15),corr_Pb.corr_dphi, yerr=corr_Pb.corr_dphi_err, linewidth=1.0,fmt='o', label='Pb')\n",
    "\n",
    "    \n",
    "\n",
    "    axs[1,j].errorbar(np.subtract(corr_D.bincenters_dphi,0.0), comp_C.ratio, yerr=comp_C.ratio_err,capsize=5, lw=3.0,fmt='o')\n",
    "    axs[1,j].errorbar(np.subtract(corr_D.bincenters_dphi,-0.05), comp_Fe.ratio, yerr=comp_Fe.ratio_err, capsize=5,lw=3.0,fmt='o')\n",
    "    axs[1,j].errorbar(np.subtract(corr_D.bincenters_dphi,-0.10), comp_Pb.ratio, yerr=comp_Pb.ratio_err, capsize=5,lw=3.0,fmt='o')\n",
    "\n",
    "    #axs[j].errorbar(corr_Fe.bincenters_dphi, corr_Fe.corr_dphi, yerr=corr_Fe.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Fe')\n",
    "    #axs[j].errorbar(corr_Pb.bincenters_dphi, corr_Pb.corr_dphi, yerr=corr_Pb.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Pb')\n",
    "    \n",
    "    axs[0,j].axhline(y=0.0,color='black',linestyle='--',alpha=0.5)\n",
    "    axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=18)\n",
    "    axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=18)\n",
    "\n",
    "    axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=18)\n",
    "    axs[1,j].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "\n",
    "    axs[0,j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=16)\n",
    "    #axs[0,j].text(1.0, 0.4, 'CLAS \\n INTERNAL', fontsize=20)\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f'%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    \n",
    "    \n",
    "    corr_D = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "    norma = np.sum(corr_D.sameh_dphi_lab.y)\n",
    "    corr_D.normalize(norma)\n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi_lab.y, yerr=corr_D.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-k',label='GiBUU D (norm)')\n",
    "    axs[0,j].legend(loc='best',frameon=False)\n",
    "\n",
    "    for target in ['C','Fe','Pb']:\n",
    "        corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "        corr.normalize(norma)\n",
    "        #axs[0,j].errorbar(corr.bincenters_dphi, corr.sameh_dphi_lab.y, yerr=corr.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label='GiBUU %s'%target)\n",
    "        \n",
    "        ratio = np.true_divide(corr.sameh_dphi_lab.y,corr_D.sameh_dphi_lab.y)\n",
    "        ratio_err = np.sqrt(np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0)\n",
    "                            +np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0))*ratio \n",
    "        \n",
    "        #comp = comparison(corr,corr_D)\n",
    "        axs[1,j].fill_between(corr.bincenters_dphi, ratio-ratio_err,ratio+ratio_err,alpha=0.5,label='GiBUU %s'%target)\n",
    "        #comp = comparison(corr,corr_D)\n",
    "        #axs[1,j].errorbar(corr.bincenters_dphi, y=ratio, linewidth=3.0,alpha=0.7,fmt='--',label='GiBUU %s'%target)\n",
    "        axs[1,j].legend(loc='upper right',frameon=False)\n",
    "    axs[1,j].set_ylim([0.5,1.25])\n",
    "\n",
    "    axs[1,j].tick_params(axis=\"x\", labelsize=16)\n",
    "    axs[1,j].tick_params(axis=\"y\", labelsize=16)\n",
    "    axs[0,j].tick_params(axis=\"x\", labelsize=16)\n",
    "    axs[0,j].tick_params(axis=\"y\", labelsize=16)             \n",
    "plt.tight_layout()\n",
    "plt.savefig('AzimuthalCorrelations_differentialz2.png')\n",
    "plt.savefig('AzimuthalCorrelations_differentialz2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azimuthal correlations for GiBUU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(1, 2,sharex=True,figsize=(12,6))\n",
    "fig1 = plt.figure(1,figsize=(8,6))\n",
    "axs = []\n",
    "axs.append(plt.gca())\n",
    "fig2= plt.figure(2,figsize=(8,6))\n",
    "axs.append(plt.gca())\n",
    "\n",
    "asso_Edges = [0.1, 0.5]\n",
    "query_trigger = 'z> %2.2f and z<= %2.2f'%(0.5,1.0)\n",
    "query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_Edges[0],asso_Edges[1])\n",
    "query_total = query_trigger + ' and '+ query_asso\n",
    "    \n",
    "    \n",
    "corr_D_GiBUU = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "norma_GiBUU = np.sum(corr_D_GiBUU.sameh_dphi_lab.y)\n",
    "corr_D_GiBUU.normalize(norma_GiBUU)\n",
    "y = corr_D_GiBUU.sameh_dphi_lab.y\n",
    "yerr = corr_D_GiBUU.sameh_dphi_lab.yerr\n",
    "x = corr_D_GiBUU.bincenters_dphi\n",
    "axs[0].fill_between(x, y-yerr,y+yerr, linewidth=3.0,alpha=0.7)\n",
    "    \n",
    "\n",
    "colors = {}\n",
    "colors['C'] = '#1f77b4'\n",
    "colors['Fe'] = '#ff7f0e'\n",
    "colors['Pb']=  '#2ca02c'\n",
    "\n",
    "##Combined deuterium for plotting purposes\n",
    "corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "axs[0].errorbar(corr_D.bincenters_dphi, corr_D.corr_dphi, yerr=corr_D.corr_dphi_err, linewidth=3.0)\n",
    "    \n",
    "for i,target in enumerate(['C','Fe','Pb']):\n",
    "    offset = int(i)*-0.04\n",
    "    ##Data\n",
    "    corr = correlation(df_trigger['%s_trigger'%target].query(query_trigger).shape[0], df['%s'%target].query(query_total), df['%s_mix'%target].query(query_total))\n",
    "    corr_ref = correlation(df_trigger['D_%s_trigger'%target].query(query_trigger).shape[0], df['D_%s'%target].query(query_total), df['D_%s_mix'%target].query(query_total))\n",
    "    norma = np.sum(corr_ref.corr_dphi)\n",
    "    corr.normalize(norma)\n",
    "    corr_ref.normalize(norma)\n",
    "    \n",
    "    axs[0].errorbar(corr.bincenters_dphi, corr.corr_dphi, yerr=corr.corr_dphi_err, lw=3.0,fmt='o')\n",
    "    \n",
    "    #comparison between D and Nuclei\n",
    "    comp = comparison(corr,corr_ref)\n",
    "    axs[1].errorbar(np.subtract(corr_ref.bincenters_dphi,offset), comp.ratio, yerr=comp.ratio_err, ms=10,lw=3.0,fmt='o',label='%s'%target)\n",
    "    axs[1].fill_between(np.subtract(corr_ref.bincenters_dphi,offset), comp.ratio*0.96,comp.ratio*1.04 ,\n",
    "                        alpha=0.2,color=colors[target])\n",
    "\n",
    "    \n",
    "    ###GIBUU    \n",
    "    corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "    corr.normalize(norma_GiBUU)\n",
    "    y = corr.sameh_dphi_lab.y\n",
    "    yerr = corr.sameh_dphi_lab.yerr\n",
    "    x  = corr.bincenters_dphi\n",
    "    axs[0].fill_between(x, y-yerr,y+yerr, linewidth=3.0,alpha=0.6)\n",
    "    ratio = np.true_divide(corr.sameh_dphi_lab.y,corr_D_GiBUU.sameh_dphi_lab.y)\n",
    "    ratio_err = np.sqrt(np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0)\n",
    "                        +np.power(np.divide(corr_D_GiBUU.sameh_dphi_lab.yerr,corr_D_GiBUU.sameh_dphi_lab.y),2.0))*ratio \n",
    "        \n",
    "    #axs[1].fill_between(corr.bincenters_dphi, ratio-ratio_err,ratio+ratio_err,alpha=0.5,label='GiBUU %s'%target)\n",
    "    axs[1].plot(corr.bincenters_dphi, ratio,alpha=0.9,label='GiBUU %s'%target,color=colors[target])\n",
    "\n",
    "        #labelling\n",
    "axs[0].axhline(y=0.0,color='black',linestyle='--',alpha=0.5)\n",
    "axs[1].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=18)\n",
    "axs[0].legend(loc='best',frameon=False)\n",
    "axs[0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=20)\n",
    "axs[1].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=20)\n",
    "#axs[1].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "axs[1].set_title('$z_{1}$> 0.5, %2.2f < $z_{2}$ < %2.2f'%(asso_Edges[0],asso_Edges[1]), fontsize=16)\n",
    "axs[1].legend(loc='lower left',frameon=False,ncol=2)\n",
    "axs[1].tick_params(axis=\"x\", labelsize=16)\n",
    "axs[1].tick_params(axis=\"y\", labelsize=16)\n",
    "#plt.text(1.5, 0.95, 'CLAS INTERNAL', fontsize=28)\n",
    "axs[1].set_ylim([0.60,1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig1.savefig('AzimuthalCorrelations_GiBUU.png')  \n",
    "plt.tight_layout()\n",
    "\n",
    "fig2.savefig('R2h_AzimuthalCorrelations_GiBUU.png')  \n",
    "fig2.savefig('R2h_AzimuthalCorrelations_GiBUU.pdf')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azimuthal correlations, various z2 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3,sharex=True,sharey='row', figsize=(14,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "#asso_Edges = [0.05,0.08, 0.15,0.3,0.5]\n",
    "asso_Edges = [0.1, 0.15,0.3,0.5]\n",
    "#asso_Edges = [0.1, 0.5]\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f'%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print (query_total)\n",
    "    \n",
    "    \n",
    "    corr_D = correlation(df_trigger['GiBUU_D_trigger'].query(query_trigger).shape[0], df['GiBUU_D'].query(query_total), df['GiBUU_D'].query(query_total))\n",
    "    norma = np.sum(corr_D.sameh_dphi_lab.y)\n",
    "    corr_D.normalize(norma)\n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi_lab.y, yerr=corr_D.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label='D',color='black')\n",
    "    \n",
    "    for target in ['C','Fe','Pb']:\n",
    "        corr = correlation(df_trigger['GiBUU_%s_trigger'%target].query(query_trigger).shape[0], df['GiBUU_%s'%target].query(query_total), df['GiBUU_%s'%target].query(query_total))\n",
    "        corr.normalize(norma)\n",
    "        axs[0,j].errorbar(corr.bincenters_dphi, corr.sameh_dphi_lab.y, yerr=corr.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o',label=target)\n",
    "        \n",
    "        ratio = np.true_divide(corr.sameh_dphi_lab.y,corr_D.sameh_dphi_lab.y)\n",
    "        ratio_err = np.sqrt(np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0)\n",
    "                            +np.power(np.divide(corr.sameh_dphi_lab.yerr,corr.sameh_dphi_lab.y),2.0))*ratio \n",
    "        \n",
    "        #comp = comparison(corr,corr_D)\n",
    "        axs[1,j].fill_between(corr.bincenters_dphi, ratio-ratio_err,ratio+ratio_err,alpha=0.7)\n",
    "        \n",
    "        #labelling\n",
    "        axs[0,j].axhline(y=0.0,color='black',linestyle='--',alpha=0.5)\n",
    "        axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=15)\n",
    "        axs[0,j].legend(loc='best',frameon=False)\n",
    "        axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=16)\n",
    "        axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=16)\n",
    "        axs[1,j].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "        axs[0,j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "        axs[0,0].tick_params(axis=\"y\", labelsize=16)\n",
    "        axs[1,0].tick_params(axis=\"y\", labelsize=16)\n",
    "\n",
    "        \n",
    "#plt.tight_layout()\n",
    "plt.savefig('AzimuthalCorrelations_GiBUU.png')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Mass vs z2 (for fixed z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4,sharex=True,sharey=True, figsize=(14,5), gridspec_kw={'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.2,0.35,0.5]\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print (query_total)\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "    \n",
    "    \n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    axs[j].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "    axs[j].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "    axs[j].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "    axs[j].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "    plt.xlim([0.3,1.8])\n",
    "\n",
    "    axs[j].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "    #axs[2].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].legend(loc='best',frameon=False)\n",
    "    axs[j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[j].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].yaxis.set_label_text(\"pdf\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dipion Mass vs z2 for fixed z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4,sharex=True, sharey=True,figsize=(14,5), gridspec_kw={'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.15,0.20,0.25]\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.4,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print (query_total)\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    \n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "\n",
    "    axs[j].plot(corr_C.hmass_x,corr_D.hmass,label='D',alpha=0.8)\n",
    "    #axs[j].plot(corr_C.hmass_x,corr_D_C.hmass_mix,label='D (mix)')\n",
    "\n",
    "    axs[j].plot(corr_C.hmass_x,corr_C.hmass,label='C',alpha=0.8)\n",
    "    axs[j].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe',alpha=0.8)\n",
    "    axs[j].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb',alpha=0.8)\n",
    "    #axs[j].fill(corr_D.hmass_x,corr_D.hmass_mix,label='(mixed)',alpha=0.4)\n",
    "    #axs[j].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='(mixed Pb)',alpha=0.4)\n",
    "\n",
    "\n",
    "    axs[j].axvline(x=0.770,linestyle='--',color='black',alpha=0.4)\n",
    "    #axs[2].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].legend(loc='best',frameon=False)\n",
    "    axs[j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[j].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "    axs[0].yaxis.set_label_text(\"pdf\")\n",
    "    plt.xlim([0.2,2.0])\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Dipion_InvariantMass_anti.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Missing Mass (z1,z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.30,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print (query_total)\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "               \n",
    "        axs[j,i].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "        axs[j,i].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "        axs[j,i].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "        axs[j,i].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "        #axs[j,i].fill(corr_Pb.hxmass_x,corr_Pb.hxmass_mix,label='(mixed)',alpha=0.4)\n",
    "\n",
    "        plt.xlim([0.0,2.0])\n",
    "\n",
    "        axs[j,i].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "        axs[3,i].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text(r'$\\frac{1}{N_{\\mathrm{trigger}}} \\mathrm{d}N_{\\mathrm{pairs}}$',fontsize=18)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass_2D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Missing Mass (z1,z1+z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.55, 0.65,0.70,0.8,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print (query_total)\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "            axs[j,i].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "            axs[j,i].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "            axs[j,i].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "            #axs[j,i].fill(corr_D.hxmass_x,corr_D.hxmass_mix,label='(mixed)',alpha=0.4)\n",
    "\n",
    "            plt.xlim([0.0,2.0])\n",
    "\n",
    "            axs[j,i].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "            axs[3,i].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Invariant Mass (z1, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.30,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print (query_total)\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "               \n",
    "        axs[j,i].plot(corr_D.hmass_x,corr_D.hmass,label='D')\n",
    "        axs[j,i].plot(corr_C.hmass_x,corr_C.hmass,label='C')\n",
    "        axs[j,i].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe')\n",
    "        axs[j,i].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb')\n",
    "        axs[j,i].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='mixed',alpha=0.4)\n",
    "        #axs[j,i].fill(corr_Fe.hmass_x,corr_Fe.hmass_mix,label='Fe (mix)',alpha=0.4)\n",
    "        \n",
    "        axs[j,i].axvline(x=0.770,color='black',alpha=0.6,linestyle='--')\n",
    "        axs[2,i].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text(r'$\\frac{1}{N_{\\mathrm{trigger}}} \\mathrm{d}N_{\\mathrm{pairs}}$',fontsize=18)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Mass_2D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Invariant Mass (z1, z1+z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D t distribution vs z1+z2 and z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.5,0.55, 0.65,0.70,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.dipion_pt_x,corr_D.dipion_pt,label='D')\n",
    "            axs[j,i].plot(corr_C.dipion_pt_x,corr_C.dipion_pt,label='C')\n",
    "            axs[j,i].plot(corr_Fe.dipion_pt_x,corr_Fe.dipion_pt,label='Fe')\n",
    "            axs[j,i].plot(corr_Pb.dipion_pt_x,corr_Pb.dipion_pt,label='Pb')\n",
    "\n",
    "#            axs[j,i].axvline(x=0.4,linestyle='--',color='black',alpha=0.6)\n",
    "            axs[3,i].xaxis.set_label_text(\"dipion pT  [GeV]$\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('t_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.15,0.25,0.4]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        axs[j,i].plot(corr_D.dipion_pt_x,corr_D.t,label='D')\n",
    "        axs[j,i].plot(corr_C.dipion_pt_x,corr_C.t,label='C')\n",
    "        axs[j,i].plot(corr_Fe.dipion_pt_x,corr_Fe.t,label='Fe')\n",
    "        axs[j,i].plot(corr_Pb.dipion_pt_x,corr_Pb.t,label='Pb')\n",
    "\n",
    "        plt.xlim([0.0,3.0])\n",
    "\n",
    "        axs[j,i].axvline(x=0.4,linestyle='--',color='black',alpha=0.6)\n",
    "        axs[3,i].xaxis.set_label_text(\"dipion pt [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('dipion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking R2h as a function of z_tot instead of z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pb'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(12,6), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "\n",
    "for target in ['C','Fe','Pb']:\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.55,maxz=1.0,variable='z_tot')\n",
    "    axs[0].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso')\n",
    "    axs[1].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    \n",
    "axs[0].legend()\n",
    "axs[0].xaxis.set_label_text(\"z_2\", fontsize=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results with and without z_tot<0.8 cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(12,6), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "\n",
    "for target in ['C','Fe','Pb']:\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso')\n",
    "    axs[0].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso',pair_cut=' and z_tot<0.8')\n",
    "    axs[1].errorbar(x,r,yerr=err,label=target,fmt='o',mfc='white',ms=8,lw=3,capsize=5)\n",
    "\n",
    "axs[1].set_title('with $z_1+z_2<$0.8', fontsize=13)\n",
    "axs[0].set_title('no cut ', fontsize=13)\n",
    "\n",
    "axs[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the dependency of the ratios on varios things like the charged of leading pion, subleading pion; Q2 and Nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid<0', pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "\n",
    "\n",
    "r, err, x  = getRatio(df['GiBUU_Pb'],df['GiBUU_D'],df_trigger['GiBUU_Pb_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='--',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_Pb'],df['GiBUU_D'],df_trigger['GiBUU_Pb_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='--',ms=8,lw=3,capsize=5)\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x  = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso<0',applyweight=True)\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid<0', pair_cut='and pid <0 and pid_asso>0',applyweight=True)\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "\n",
    "r, err, x  = getRatio(df['GiBUU_Fe'],df['GiBUU_D'],df_trigger['GiBUU_Fe_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='--',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_Fe'],df['GiBUU_D'],df_trigger['GiBUU_Fe_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='--',ms=8,lw=3,capsize=5)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "#plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='--',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='--',ms=8,lw=3,capsize=5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same sign results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='C, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='Fe, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='Pb, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Varying Nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12, 10))\n",
    "\n",
    "for i, target in enumerate(['D','C','Fe','Pb']):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.hist(df[target].query('z>0.5 and pid_asso>0')['z_asso'], bins=100,range =(0,0.5),label='$\\pi^+$',alpha=0.5)\n",
    "    plt.hist(df[target].query('z>0.5 and pid_asso<0')['z_asso'], bins=100,range =(0,0.5),label='$\\pi^-$',alpha=0.5)\n",
    "\n",
    "    plt.title('%s, Conditional for $z_{1}>0.5$'%target)\n",
    "    plt.ylabel('pairs',fontsize=16)\n",
    "    plt.xlabel('$z_{2}$',fontsize=16)\n",
    "    plt.legend(frameon=False)    \n",
    "\n",
    "plt.savefig('ConditionalDistribution_z2_BothPions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z distribution of triggers by charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12, 10))\n",
    "\n",
    "for i, target in enumerate(['D','C','Fe','Pb']):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.hist(df_trigger['%s_trigger'%target].query('z>0.5 and pid>0')['z'], bins=100,range =(0.5,1.0),label='$\\pi^+$',alpha=0.5)\n",
    "    plt.hist(df_trigger['%s_trigger'%target].query('z>0.5 and pid<0')['z'], bins=100,range =(0.5,1.0),label='$\\pi^-$',alpha=0.5)\n",
    "\n",
    "    plt.ylabel('pairs',fontsize=16)\n",
    "    plt.xlabel('$z_{1}$',fontsize=16)\n",
    "    plt.legend(frameon=False)    \n",
    "\n",
    "plt.savefig('Triggers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Pb'].query('z>0.5 and pid_asso>0')['P_asso'], bins=30,range =(0,1.5),label='pi+',alpha=0.5)\n",
    "plt.hist(df['Pb'].query('z>0.5 and pid_asso<0')['P_asso'], bins=30,range =(0,1.5),label='pi-',alpha=0.5)\n",
    "\n",
    "plt.title('Conditional distribution for $z_{1}>0.5$',fontsize=16)\n",
    "plt.ylabel('pairs',fontsize=16)\n",
    "plt.xlabel('$P_{2}$',fontsize=16)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('ConditionalDistributionMomentum_Deuterium.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
