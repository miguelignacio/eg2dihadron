{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TFile\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pandas as pd \n",
    "import time\n",
    "import root_pandas as rpd\n",
    "from root_pandas import read_root\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 6.2,3.5\n",
    "mpl.rcParams['axes.labelsize'] = 17\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['lines.markersize'] = 6\n",
    "mpl.rcParams['legend.fontsize']= 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class correlation:\n",
    "    def __init__(self, ntriggers, df, df_mixed):\n",
    "        \n",
    "        self.nbins_dphi = 18#32\n",
    "        self.nbins_deta = 18#16\n",
    "        self.ntriggers = ntriggers\n",
    "        self.phibins = np.linspace(0, np.pi, self.nbins_dphi+1)#16+1) #was 16+1\n",
    "        #        self.phibins = np.linspace(-np.pi, np.pi, self.nbins_dphi+1)#16+1) #was 16+1\n",
    "        #self.etabins = np.linspace(-np.pi, np.pi, self.nbins_deta+1)#16+1) #was 16+1\n",
    "        self.etabins = np.linspace(-0.5, 4, self.nbins_deta+1) #was 16+1        \n",
    "        \n",
    "        \n",
    "        self.bincenters_dphi = [np.mean([x, y]) for (x, y) in zip(self.phibins[:-1], self.phibins[1:])]\n",
    "        self.bincenters_deta = [np.mean([x, y]) for (x, y) in zip(self.etabins[:-1], self.etabins[1:])]\n",
    "        \n",
    "        dphi = list(df['dphi'])\n",
    "        dphi_lab = list(df['dphi_lab'])\n",
    "        deta = list(df['dy'])\n",
    "        mixed_dphi = list(df_mixed['dphi'])\n",
    "        mixed_dphi_lab = list(df_mixed['dphi_lab'])\n",
    "        mixed_deta = list(df_mixed['dy'])\n",
    "        \n",
    "        self.numberofpairs = df.shape[0]\n",
    "        \n",
    "        #1D correlations\n",
    "        #dphi\n",
    "        self.sameh_dphi =myHisto(dphi, self.phibins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_dphi.norm(ntriggers)   \n",
    "        self.mixh_dphi  =myHisto(mixed_dphi, self.phibins)\n",
    "        norm = sum(self.mixh_dphi.y)/self.nbins_dphi\n",
    "        self.mixh_dphi.norm(norm)\n",
    "        self.corr_dphi = np.true_divide(self.sameh_dphi.y,self.mixh_dphi.y)\n",
    "        self.corr_dphi_err = np.true_divide(self.sameh_dphi.yerr,self.mixh_dphi.y)\n",
    "\n",
    "        #dphi in lab frame\n",
    "        self.sameh_dphi_lab =myHisto(dphi_lab, self.phibins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_dphi_lab.norm(ntriggers)   \n",
    "        self.mixh_dphi_lab  =myHisto(mixed_dphi_lab, self.phibins)\n",
    "        norm = sum(self.mixh_dphi_lab.y)/self.nbins_dphi\n",
    "        self.mixh_dphi_lab.norm(norm)\n",
    "        self.corr_dphi_lab = np.true_divide(self.sameh_dphi_lab.y,self.mixh_dphi_lab.y)\n",
    "        self.corr_dphi_lab_err = np.true_divide(self.sameh_dphi_lab.yerr,self.mixh_dphi_lab.y)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.sameh_deta =myHisto(deta, self.etabins) # np.histogram(dphi, self.phibins)[0]\n",
    "        self.sameh_deta.norm(ntriggers)\n",
    "        self.mixh_deta  =myHisto(mixed_deta, self.etabins)\n",
    "        norm = sum(self.mixh_deta.y)/self.nbins_deta #sum(self.mixh_deta.y)/self.nbins_deta\n",
    "        self.mixh_deta.norm(norm)\n",
    "        #self.corr_deta     = np.true_divide(self.sameh_deta.y,self.mixh_deta.y)\n",
    "        #self.corr_deta_err = np.true_divide(self.sameh_deta.yerr,self.mixh_deta.y)\n",
    "\n",
    "        # 2D correlations\n",
    "        \n",
    "        #self.sameh_2d, self.xedges,self.yedges = np.histogram2d(deta,dphi, [self.etabins,self.phibins])\n",
    "        #self.mixh_2d, self.xedges,self.yedges = np.histogram2d(mixed_deta,mixed_dphi, [self.etabins,self.phibins])\n",
    "\n",
    "        #get correlation function\n",
    "        #self.corr_2d = np.true_divide(self.sameh_2d,self.mixh_2d)\n",
    "        #self.extent = [self.xedges[0], self.xedges[-1], self.yedges[0], self.yedges[-1]]\n",
    "        \n",
    "        #MASS: \n",
    "        self.hmass, self.hmass_x = np.histogram(df['mass'],range=(0.0,2.0),density=True, bins=50)\n",
    "        self.hmass_mix, self.hmass_x = np.histogram(df_mixed['mass'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.hmass_x = (self.hmass_x[1:] + self.hmass_x[:-1])/2.0\n",
    "        \n",
    "        self.hxmass, self.hxmass_x = np.histogram(df['missing_mass'],range=(0.0,2.0),density= True, bins=50)\n",
    "        self.hxmass_mix, self.hxmass_x = np.histogram(df_mixed['missing_mass'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.hxmass_x = (self.hxmass_x[1:] + self.hxmass_x[:-1])/2.0\n",
    "        \n",
    "        self.t, self.t_x = np.histogram(df['t'],range=(0.0,5.0), density= True, bins=50)\n",
    "        self.t_mix, self.t_x = np.histogram(df_mixed['t'],range=(0.0,5.0),density=True,bins=50)\n",
    "        self.t_x = (self.t_x[1:] + self.t_x[:-1])/2.0\n",
    "        \n",
    "        self.dipion_pt, self.dipion_pt_x = np.histogram(df['dipion_pt'],range=(0.0,2.0), density = True, bins=50)\n",
    "        self.dipion_pt_mix, self.dipion_pt_x = np.histogram(df_mixed['dipion_pt'],range=(0.0,2.0),density=True,bins=50)\n",
    "        self.dipion_pt_x = (self.dipion_pt_x[1:] + self.dipion_pt_x[:-1])/2.0\n",
    "        \n",
    "\n",
    "    def normalize(self,norma):\n",
    "        #print 'sum entrifes beforoe normalization' ,np.sum(self.corr_dphi)\n",
    "        #print 'requested normalization' , norma\n",
    "        self.corr_dphi     = np.true_divide(self.corr_dphi, norma)\n",
    "        #print ' sum entries after normalization', np.sum(self.corr_dphi)\n",
    "        self.corr_dphi_err = np.true_divide(self.corr_dphi_err,norma)\n",
    "        return \n",
    "\n",
    "class comparison:\n",
    "    def __init__(self, corr_A, corr_D):\n",
    "        \n",
    "        self.corr_A = corr_A.corr_dphi\n",
    "        self.corr_D = corr_D.corr_dphi\n",
    "        self.err_A  = corr_A.corr_dphi_err\n",
    "        self.err_D  = corr_D.corr_dphi_err\n",
    "        self.dif_err = np.sqrt(np.power(self.err_A,2.0)+np.power(self.err_D,2.0)) #error for difference\n",
    "        self.diff  = np.subtract(self.corr_A,self.corr_D)\n",
    "        self.ratio = np.true_divide(self.corr_A,self.corr_D)\n",
    "        self.ratio_err = np.sqrt(np.power(np.divide(self.err_A,self.corr_A),2.0)+np.power(np.divide(self.err_D,self.corr_D),2.0))*self.ratio \n",
    "        \n",
    "        \n",
    "class myHisto:\n",
    "    def __init__(self, data, bins):\n",
    "        self.bins = bins\n",
    "        self.y    = np.histogram(data, self.bins)[0]\n",
    "        self.yerr = np.sqrt(self.y)\n",
    "    def norm(self, norm=1.0):\n",
    "        self.y = np.true_divide(self.y, norm)\n",
    "        self.yerr = np.true_divide(self.yerr, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRatio(df_A,df_D,df_trigger_A,df_trigger_D, variable='z_asso',trig_cut = 'z>0.5', pair_cut='',minz=0.05,maxz=0.5,nbins=12):\n",
    "    #get number of pions with z>0.5\n",
    "    norm_A = df_trigger_A.query(trig_cut).shape[0]\n",
    "    norm_D = df_trigger_D.query(trig_cut).shape[0]\n",
    "    y_A, x_conditional = np.histogram(df_A.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "    y_D, x_conditional = np.histogram(df_D.query(trig_cut+pair_cut)[variable],bins=np.logspace(np.log10(minz), np.log10(maxz),nbins))\n",
    "    x_conditional = (x_conditional[1:] + x_conditional[:-1])/2.0\n",
    "    err_A = np.true_divide(np.sqrt(y_A),y_A)\n",
    "    err_D = np.true_divide(np.sqrt(y_D),y_D)\n",
    "    y_A = np.true_divide(y_A,norm_A)\n",
    "    y_D = np.true_divide(y_D,norm_D)\n",
    "    ratio_conditional = np.true_divide(y_A,y_D)\n",
    "    error_conditional = np.multiply(ratio_conditional, np.sqrt(np.power(err_A,2.0) + np.power(err_D,2.0)))\n",
    "    \n",
    "    return ratio_conditional,error_conditional,x_conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCut(inputDataframe, cut, text=None):\n",
    "    nbeforecut = inputDataframe.shape[0]\n",
    "    cutDataframe = inputDataframe.query(cut)\n",
    "    if text:\n",
    "        print text, cutDataframe.shape[0], ' (%2.2f '%(100.0*cutDataframe.shape[0]/nbeforecut), '%)'\n",
    "    return cutDataframe\n",
    "def applyCuts(fullDataframe,name='default',isMC=False): \n",
    "    dataframe = fullDataframe\n",
    "    print 'Entries before cut ', dataframe.shape[0]\n",
    "    dataframe.eval('inelasticity = Nu/5.014', inplace=True)\n",
    "    dataframe.eval('E = z*Nu', inplace=True)\n",
    "    dataframe.eval('P = sqrt(E*E-0.140*0.140)', inplace=True)\n",
    "    \n",
    "    dataframe = applyCut(dataframe, 'Q2>1.0', 'Q2>1.0 :')\n",
    "    #dataframe = applyCut(dataframe, 'W>2.0', 'W>2.0 :')\n",
    "    #dataframe = applyCut(dataframe, 'Nu>3.5', 'Nu>3.5 :')\n",
    "\n",
    "    dataframe = applyCut(dataframe, 'z>0.5', 'z>0.5 :')\n",
    "    dataframe = applyCut(dataframe, 'P <2.5 ', 'P<2.5 ')\n",
    "    dataframe = applyCut(dataframe, 'inelasticity<0.85','inelasticity < 0.85')\n",
    "    return dataframe\n",
    "\n",
    "def applyCutsPair(fullDataframe,name='default'):\n",
    "    print 'Starting election on dipion variables'\n",
    "    dataframe = fullDataframe\n",
    "    dataframe.eval('z_tot = z+z_asso', inplace=True)\n",
    "    dataframe.eval('E_asso = z_asso*Nu', inplace=True)\n",
    "    dataframe.eval('P_asso = sqrt(E_asso*E_asso-0.140*0.140)', inplace=True)\n",
    "    #dataframe = applyCut(dataframe, 'z+z_asso<0.8', 'z+z_asso<0.8')\n",
    "    return dataframe\n",
    "\n",
    "def printPairBreakdown(dataframe):\n",
    "    \n",
    "    print 'Pairs with Leading pi+', dataframe.query('pid==211').shape[0]\n",
    "    print 'Pairs with Leading pi-', dataframe.query('pid==-211').shape[0]\n",
    "    print 'Pairs with Sub-Leading pi+', dataframe.query('pid_asso==211').shape[0]\n",
    "    print 'Pairs with Sub-Leading pi-', dataframe.query('pid_asso==-211').shape[0]\n",
    "    print 'pi+ pi+ pairs',dataframe.query('pid==211 and pid_asso==211').shape[0]\n",
    "    print 'pi- pi- pairs',dataframe.query('pid==-211 and pid_asso==-211').shape[0]\n",
    "    print 'pi+ pi- pairs',dataframe.query('pid==211 and pid_asso==-211').shape[0]\n",
    "    print 'pi- pi+ pairs',dataframe.query('pid==-211 and pid_asso==211').shape[0]\n",
    "    print '//////////////////////////////////////////////////////'\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from Ntuples to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this needs to be read in chunks otherwise it uses all memory. (from https://github.com/scikit-hep/root_pandas)\n",
    "def getdatainChunks(filename,treename):\n",
    "    dataframe =pd.DataFrame()\n",
    "    for df in read_root(filename, treename, chunksize=100000) :\n",
    "        #print df.shape[0]\n",
    "        dataframe = pd.concat([dataframe,df])\n",
    "    \n",
    "    print dataframe.shape[0]\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataframes from target C\n",
      "294942\n",
      "1529559\n",
      "395135\n",
      "1983833\n",
      "Get trigger dataframes from targetC\n",
      "1218503\n",
      "1599452\n",
      "Getting dataframes from target Fe\n",
      "401683\n",
      "2201072\n",
      "715969\n"
     ]
    }
   ],
   "source": [
    "df = {}\n",
    "df_trigger = {}\n",
    "\n",
    "for target in ['C','Fe','Pb']:\n",
    "    print 'Getting dataframes from target %s'%target\n",
    "    df[target]=getdatainChunks('Pairs_%s.root'%target, target)\n",
    "    df['%s_mix'%target] = getdatainChunks('Pairs_%s.root'%target, '%s_mix'%target)\n",
    "    df['D_%s'%target]= getdatainChunks('Pairs_%s.root'%target, 'D_%s'%target)\n",
    "    df['D_%s_mix'%target] = getdatainChunks('Pairs_%s.root'%target, 'D_%s_mix'%target)\n",
    "    \n",
    "    print 'Get trigger dataframes from target%s'%target\n",
    "    df_trigger['%s_trigger'%target] = getdatainChunks('Pairs_%s.root'%target, '%s_trigger'%target)\n",
    "    df_trigger['D_%s_trigger'%target] = getdatainChunks('Pairs_%s.root'%target, 'D_%s_trigger'%target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GiBUU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in ['D','C','Fe']:#,'Fe','C']:\n",
    "    #GiBUU\n",
    "    df['GiBUU_%s'%target]= getdatainChunks('GiBUU_Pairs_%s.root'%target, target)\n",
    "    df_trigger['GiBUU_%s_trigger'%target]= getdatainChunks('GiBUU_Pairs_%s.root'%target, '%s_trigger'%target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the deuterium datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['D'] = pd.concat([df['D_Pb'],df['D_Fe'],df['D_C']]) #simply combine the deuterium results for all targets\n",
    "df['D_mix'] = pd.concat([df['D_Pb_mix'],df['D_Fe_mix'],df['D_C_mix']]) #simply combine the deuterium results for all targets\n",
    "df_trigger['D_trigger'] = pd.concat([df_trigger['D_Pb_trigger'],df_trigger['D_Fe_trigger'],df_trigger['D_C_trigger']]) #simply combine the deuterium results for all targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframees with pairs\n",
    "for key in df.keys():\n",
    "    print key\n",
    "    df[key] = applyCuts(df[key])\n",
    "    printPairBreakdown(df[key])\n",
    "    df[key] = applyCutsPair(df[key])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply cuts for trigger dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_trigger.keys():\n",
    "    print key\n",
    "    df_trigger[key] = applyCuts(df_trigger[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get R_2h for various selections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nominal (no selection)\n",
    "r_C, err_C,x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'])\n",
    "r_Fe, err_Fe,x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'])\n",
    "r_Pb, err_Pb,x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R_2h for MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rMC_C, rMC_err_C,x = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get R_2h in different mass bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mass\n",
    "r_C_low, err_C_low,x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],pair_cut=' and mass<0.6')\n",
    "r_Fe_low, err_Fe_low,x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],pair_cut=' and mass<0.6')\n",
    "r_Pb_low, err_Pb_low,x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],pair_cut=' and mass<0.6')\n",
    "\n",
    "r_C_middle, err_C_middle,x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],pair_cut=' and mass<1.0 and mass>0.6')\n",
    "r_Fe_middle, err_Fe_middle,x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],pair_cut=' and mass<1.0 and mass>0.6')\n",
    "r_Pb_middle, err_Pb_middle,x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],pair_cut=' and mass<1.0 and mass>0.6')\n",
    "\n",
    "r_C_high, err_C_high,x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],pair_cut=' and mass>1.0 and mass<1.5')\n",
    "r_Fe_high, err_Fe_high,x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],pair_cut=' and mass>1.0 and mass<1.5')\n",
    "r_Pb_high, err_Pb_high,x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],pair_cut=' and mass>1.0 and mass<1.5')\n",
    "\n",
    "r_C_veryhigh, err_C_veryhigh,x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],pair_cut=' and mass>1.0 and mass<1.5')\n",
    "r_Fe_veryhigh, err_Fe_veryhigh,x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],pair_cut=' and mass>1.0 and mass<1.5')\n",
    "r_Pb_veryhigh, err_Pb_veryhigh,x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],pair_cut=' and mass>1.0 and mass<1.5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R_2h data from HERMES and Neutrino buble-chamber experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hermes data:\n",
    "hermes_y = {}\n",
    "hermes_ystat = {}\n",
    "hermes_ysyst = {}\n",
    "hermes_ytotal = {}\n",
    "\n",
    "#DATA FROM SELECTIO1 OF http://www-hermes.desy.de/notes/pub/publications.html\n",
    "hermes_x = {}\n",
    "hermes_x['Kr'] = [0.09,0.15,0.24,0.35,0.44]\n",
    "hermes_x['N'] = np.subtract(hermes_x['Kr'],0.003)\n",
    "hermes_x['Xe'] = np.subtract(hermes_x['Kr'],-0.003)\n",
    "\n",
    "#nitrogen, atomic number 7\n",
    "hermes_y['N']     = [1.0324, 0.9781,0.9293,0.8678,0.8822]\n",
    "hermes_ystat['N'] = [0.0767,0.0268,0.0323,0.0478,0.0601]\n",
    "hermes_ysyst['N'] = [0.0206,0.0196,0.0186,0.0174,0.0176]\n",
    "hermes_ytotal['N'] = np.sqrt(np.power(hermes_ystat['N'],2.0)+np.power(hermes_ysyst['N'],2.0))\n",
    "\n",
    "#krypton, atomic number 36\n",
    "hermes_y['Kr'] = [1.2072,0.9180,0.8822,0.8631,1.0314]\n",
    "hermes_ystat['Kr'] = [0.1342,0.0366,0.0452,0.0661,0.0972]\n",
    "hermes_ysyst['Kr'] =[0.0241,0.0184,0.0176,0.0173,0.0206]\n",
    "hermes_ytotal['Kr'] = np.sqrt(np.power(hermes_ystat['Kr'],2.0)+np.power(hermes_ysyst['Kr'],2.0))\n",
    "\n",
    "hermes_y['Xe'] = [1.1648,0.9345,0.9242,0.8128,0.9373]\n",
    "hermes_ystat['Xe'] = [0.1205,0.0359,0.0433,0.0614,0.0808]\n",
    "hermes_ysyst['Xe'] = [0.0233,0.0187,0.0185,0.0163,0.0187]\n",
    "hermes_ytotal['Xe'] = np.sqrt(np.power(hermes_ystat['Xe'],2.0)+np.power(hermes_ysyst['Xe'],2.0))\n",
    "\n",
    "\n",
    "neutrino_x = [0.10763636363636367, 0.18618181818181817,0.25163636363636366,0.3345454545454546]\n",
    "neutrino_y = [1.4535664335664338, 1.0148378893833438,  1.0373426573426574, 0.8784361093452003]\n",
    "neutrino_yerror =[1.5794405594405596, 1.112739987285442, 1.1422377622377624,1.004310235219326]\n",
    "neutrino_yerror = np.subtract(neutrino_yerror,neutrino_y)\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "\n",
    "plt.errorbar(hermes_x['N'], hermes_y['N'],yerr=hermes_ytotal['N'],label='Hermes, $^{14}N$',fmt='o')\n",
    "plt.errorbar(hermes_x['Kr'], hermes_y['Kr'],yerr=hermes_ytotal['Kr'],label='Hermes, $^{84}Kr$',fmt='o')\n",
    "plt.errorbar(hermes_x['Xe'], hermes_y['Xe'],yerr=hermes_ytotal['Xe'],label='Hermes, $^{131}Xe$',fmt='o')\n",
    "plt.errorbar(neutrino_x, neutrino_y,yerr=neutrino_yerror,label='SKAT, $A_{eff}=21$',fmt='o')\n",
    "plt.xlabel('$z_{2}$',fontsize=18)\n",
    "plt.ylabel('$R_{2h}$',fontsize=18)\n",
    "plt.axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig('PreviousData.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.errorbar(x+0.002,r_C,yerr=err_C,label='This work,  $^{12}_{6}C$',fmt='ro',ms=8,lw=3,capsize=5)\n",
    "#plt.errorbar(x,r_Fe,yerr=err_Fe,label='This work,  $^{56}_{26}Fe$',fmt='bo',ms=8,lw=3,capsize=5)\n",
    "#plt.errorbar(x-0.002,r_Pb,yerr=err_Pb,label='This work,  $^{208}_{82}Pb$',fmt='go',ms=8,lw=3,capsize=5)\n",
    "plt.errorbar(hermes_x['N'], hermes_y['N'],yerr=hermes_ytotal['N'],fmt='o',label='HERMES, $^{14}_{7}N$',fillstyle=None,ms=8,capsize=5)\n",
    "#plt.errorbar(hermes_x['Kr'], hermes_y['Kr'],yerr=hermes_ytotal['Kr'],fmt='o',label='HERMES, $^{84}_{36}Kr$',fillstyle=None,ms=8,capsize=5)\n",
    "#plt.errorbar(hermes_x['Xe'], hermes_y['Xe'],yerr=hermes_ytotal['Xe'],fmt='o',label='HERMES, $^{131}_{54}Xe$',fillstyle=None,ms=8,capsize=5)\n",
    "#plt.errorbar(neutrino_x, neutrino_y,yerr=neutrino_yerror,fmt='s',mfc='white',label='Neutrino, $A_{eff}=21$',fillstyle=None,ms=8,capsize=5)\n",
    "\n",
    "\n",
    "plt.errorbar(x+0.002,rMC_C,yerr=rMC_err_C,label='GiBUU $^{12}_{6}C$',ms=8,lw=3,capsize=5)\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('$z_{2}$',fontsize=18)\n",
    "plt.ylabel('$R_{2h}$',fontsize=18)\n",
    "\n",
    "#plt.ylim([0.5,1.5])\n",
    "plt.xlim([0.00,0.5])\n",
    "\n",
    "\n",
    "plt.axhline(y=1.0,color='red',linestyle='--')\n",
    "plt.legend(loc='best',frameon=False,fontsize=15,ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ComparisonWithHermes_Linear.png')\n",
    "\n",
    "\n",
    "plt.xlim([0.05,0.5])\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.savefig('ComparisonWithHermes_Log.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional z2 distribution ratio for z>0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2h in mass bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3,sharex=True, sharey=True, figsize=(14,5), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "\n",
    "\n",
    "mpl.rcParams['axes.labelsize'] = 17\n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['lines.markersize'] = 8\n",
    "mpl.rcParams['errorbar.capsize'] = 5\n",
    "mpl.rcParams['legend.fontsize']= 15\n",
    "\n",
    "axs[0].errorbar(x,r_C_low,yerr=err_C_low,label='C',fmt='og')\n",
    "axs[0].errorbar(x-0.003,r_Fe_low,yerr=err_Fe_low,label='Fe',fmt='ob')\n",
    "axs[0].errorbar(x+0.003,r_Pb_low,yerr=err_Pb_low,label='Pb',fmt='or')\n",
    "axs[0].legend(frameon=False)\n",
    "axs[0].axhline(y=1.0,color='black',linestyle='--')\n",
    "axs[0].set_title('0.3< $M_{\\pi\\pi}$ <0.6 GeV',fontsize=16)\n",
    "plt.xscale('log')\n",
    "#plt.ylim([0.5,1.5])\n",
    "\n",
    "plt.xlim([0.05,0.5])\n",
    "\n",
    "axs[1].errorbar(x,r_C_middle,yerr=err_C_middle,label='C',fmt='og')\n",
    "axs[1].errorbar(x-0.003,r_Fe_middle,yerr=err_Fe_middle,label='Fe',fmt='ob')\n",
    "axs[1].errorbar(x+0.003,r_Pb_middle,yerr=err_Pb_middle,label='Pb',fmt='or')\n",
    "axs[1].axhline(y=1.0,color='black',linestyle='--')\n",
    "axs[1].set_title('0.6< $M_{\\pi\\pi}$ <1.0 GeV',fontsize=16)\n",
    "axs[1].legend(frameon=False)\n",
    "\n",
    "axs[2].errorbar(x,r_C_high,yerr=err_C_high,label='C',fmt='og')\n",
    "axs[2].errorbar(x-0.003,r_Fe_high,yerr=err_Fe_high,label='Fe',fmt='ob')\n",
    "axs[2].errorbar(x+0.003,r_Pb_high,yerr=err_Pb_high,label='Pb',fmt='or')\n",
    "axs[2].axhline(y=1.0,color='black',linestyle='--')\n",
    "axs[2].set_title('1.0 < $M_{\\pi\\pi}$ <1.5 GeV',fontsize=16)\n",
    "axs[2].legend(frameon=False)\n",
    "\n",
    "##axs[3].errorbar(x,r_C_veryhigh,yerr=err_C_veryhigh,label='C',fmt='og')\n",
    "##axs[3].errorbar(x-0.003,r_Fe_veryhigh,yerr=err_Fe_veryhigh,label='Fe',fmt='ob')\n",
    "##axs[3].errorbar(x+0.003,r_Pb_veryhigh,yerr=err_Pb_veryhigh,label='Pb',fmt='or')\n",
    "##axs[3].axhline(y=1.0,color='black',linestyle='--')\n",
    "##axs[3].set_title('1.5 < $M_{\\pi\\pi}$ <2.0 GeV')\n",
    "##axs[3].legend(frameon=False)\n",
    "\n",
    "axs[0].xaxis.set_label_text('$z_{2}$',fontsize=18)\n",
    "axs[1].xaxis.set_label_text('$z_{2}$',fontsize=18)\n",
    "axs[2].xaxis.set_label_text('$z_{2}$',fontsize=18)\n",
    "\n",
    "axs[0].yaxis.set_label_text('$R_{2h}$',fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('R2h_massdependence.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Mixing corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(14,8))\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.3,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    print df_trigger['Pb_trigger'].query(query_trigger).shape[0]\n",
    "    corr = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    \n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi.y, yerr=corr_D.sameh_dphi.yerr, linewidth=3.0,alpha=0.7,fmt='-o', label='Uncorrected')\n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.corr_dphi, yerr=corr_D.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Corrected')\n",
    "\n",
    "    axs[0,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=15)\n",
    "    axs[0,j].legend(loc='best',frameon=False)\n",
    "    axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=16)\n",
    "    axs[0,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "    axs[1,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[1,j].errorbar(corr_D.bincenters_dphi, corr_D.mixh_dphi.y, yerr=corr_D.mixh_dphi.yerr, linewidth=3.0,alpha=0.7,fmt='-ko', label='Mixed Events')\n",
    "    axs[1,0].yaxis.set_label_text('norm units',fontsize=16)\n",
    "    axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=15)\n",
    "    axs[1,j].legend(loc='best',frameon=False)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('EventMixing_AzimuthalCorrelations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event mixing corrections for lab frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4,figsize=(14,8))\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.3,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    print df_trigger['Pb_trigger'].query(query_trigger).shape[0]\n",
    "    corr = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    \n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.sameh_dphi_lab.y, yerr=corr_D.sameh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-o', label='Uncorrected')\n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.corr_dphi_lab, yerr=corr_D.corr_dphi_lab_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Corrected')\n",
    "\n",
    "    axs[0,j].xaxis.set_label_text(\"|$\\Delta\\phi_{lab}$|  [rad]\", fontsize=15)\n",
    "    axs[0,j].legend(loc='best',frameon=False)\n",
    "    axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{lab})/M(z_{1}>0.5)$',fontsize=16)\n",
    "    axs[0,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "    axs[1,j].set_title('%2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[1,j].errorbar(corr_D.bincenters_dphi, corr_D.mixh_dphi_lab.y, yerr=corr_D.mixh_dphi_lab.yerr, linewidth=3.0,alpha=0.7,fmt='-ko', label='Mixed Events')\n",
    "    axs[1,0].yaxis.set_label_text('norm units',fontsize=16)\n",
    "    axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{lab}$|  [rad]\", fontsize=15)\n",
    "    axs[1,j].legend(loc='best',frameon=False)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('EventMixing_AzimuthalCorrelations_LabFrame.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azimuthal correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4,sharex=True,sharey='row', figsize=(14,8), gridspec_kw={'wspace':0, 'hspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.3,0.5]\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f and pid>0 '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f and pid>0 and pid_asso>0'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    ##Combined deuterium for plotting purposes\n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "    \n",
    "    #plots:\n",
    "    #correlations\n",
    "    \n",
    "    axs[0,j].errorbar(corr_D.bincenters_dphi, corr_D.corr_dphi, yerr=corr_D.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-ko', label='D')\n",
    "    axs[0,j].errorbar(corr_C.bincenters_dphi, corr_C.corr_dphi, yerr=corr_C.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-ro', label='C')\n",
    "    axs[0,j].errorbar(corr_Fe.bincenters_dphi, corr_Fe.corr_dphi, yerr=corr_Fe.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-bo', label='Fe')\n",
    "    axs[0,j].errorbar(corr_Pb.bincenters_dphi, corr_Pb.corr_dphi, yerr=corr_Pb.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-go', label='Pb')\n",
    "\n",
    "    \n",
    "    axs[1,j].errorbar(corr_D.bincenters_dphi, comp_C.ratio, yerr=comp_C.ratio_err, linewidth=3.0,alpha=0.7,fmt='-ro')\n",
    "    axs[1,j].errorbar(corr_D.bincenters_dphi, comp_Fe.ratio, yerr=comp_Fe.ratio_err, linewidth=3.0,alpha=0.7,fmt='-bo')\n",
    "    axs[1,j].errorbar(corr_D.bincenters_dphi, comp_Pb.ratio, yerr=comp_Pb.ratio_err, linewidth=3.0,alpha=0.7,fmt='-go')\n",
    "\n",
    "    #axs[j].errorbar(corr_Fe.bincenters_dphi, corr_Fe.corr_dphi, yerr=corr_Fe.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Fe')\n",
    "    #axs[j].errorbar(corr_Pb.bincenters_dphi, corr_Pb.corr_dphi, yerr=corr_Pb.corr_dphi_err, linewidth=3.0,alpha=0.7,fmt='-o', label='Pb')\n",
    "    \n",
    "    axs[0,j].axhline(y=0.0,color='black',linestyle='--',alpha=0.5)\n",
    "    axs[1,j].xaxis.set_label_text(\"|$\\Delta\\phi_{pq}$|  [rad]\", fontsize=15)\n",
    "    axs[0,j].legend(loc='best',frameon=False)\n",
    "    axs[0,0].yaxis.set_label_text(r'$M(z_{2}|z_{1}, \\Delta\\phi_{pq})/M(z_{1}>0.5)$',fontsize=16)\n",
    "\n",
    "    axs[1,0].yaxis.set_label_text(r'$R_{2h}(z_{1},z_{2}, \\Delta\\phi_{pq}) $',fontsize=16)\n",
    "    axs[1,j].axhline(y=1.0,color='black',linestyle='--',alpha=0.5)\n",
    "\n",
    "    axs[0,j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('AzimuthalCorrelations.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Mass vs z2 (for fixed z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4,sharex=True,sharey=True, figsize=(14,5), gridspec_kw={'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.2,0.35,0.5]\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.5,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "    \n",
    "    \n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    axs[j].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "    axs[j].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "    axs[j].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "    axs[j].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "    plt.xlim([0.3,1.8])\n",
    "\n",
    "    axs[j].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "    #axs[2].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].legend(loc='best',frameon=False)\n",
    "    axs[j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[j].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].yaxis.set_label_text(\"pdf\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dipion Mass vs z2 for fixed z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4,sharex=True, sharey=True,figsize=(14,5), gridspec_kw={'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.15,0.20,0.25]\n",
    "#asso_Edges =np.logspace(np.log10(0.05), np.log10(0.5),5)\n",
    "\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    query_trigger = 'z> %2.2f and z<= %2.2f '%(0.4,1.0)\n",
    "    query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "    query_total = query_trigger + ' and '+ query_asso\n",
    "    print query_total\n",
    "    \n",
    "    corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "    corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "    norma = np.sum(corr_D_C.corr_dphi)\n",
    "    corr_D_C.normalize(norma)\n",
    "    corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "    corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "    corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "    corr_Pb.normalize(norma)\n",
    "    corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "    corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "    corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "    norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "    corr_Fe.normalize(norma)\n",
    "    corr_D_Fe.normalize(norma)\n",
    "\n",
    "    comp_C = comparison(corr_C,corr_D_C)\n",
    "    comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "    comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "\n",
    "    \n",
    "    corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "    corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "\n",
    "    axs[j].plot(corr_C.hmass_x,corr_D.hmass,label='D',alpha=0.8)\n",
    "    #axs[j].plot(corr_C.hmass_x,corr_D_C.hmass_mix,label='D (mix)')\n",
    "\n",
    "    axs[j].plot(corr_C.hmass_x,corr_C.hmass,label='C',alpha=0.8)\n",
    "    axs[j].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe',alpha=0.8)\n",
    "    axs[j].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb',alpha=0.8)\n",
    "    #axs[j].fill(corr_D.hmass_x,corr_D.hmass_mix,label='(mixed)',alpha=0.4)\n",
    "    #axs[j].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='(mixed Pb)',alpha=0.4)\n",
    "\n",
    "\n",
    "    axs[j].axvline(x=0.770,linestyle='--',color='black',alpha=0.4)\n",
    "    #axs[2].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "    axs[j].legend(loc='best',frameon=False)\n",
    "    axs[j].set_title('$z_{1}$> 0.5 \\n %2.2f < $z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "    axs[j].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "    axs[0].yaxis.set_label_text(\"pdf\")\n",
    "    plt.xlim([0.2,2.0])\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Dipion_InvariantMass_anti.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Missing Mass (z1,z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.30,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "               \n",
    "        axs[j,i].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "        axs[j,i].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "        axs[j,i].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "        axs[j,i].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "        #axs[j,i].fill(corr_Pb.hxmass_x,corr_Pb.hxmass_mix,label='(mixed)',alpha=0.4)\n",
    "\n",
    "        plt.xlim([0.0,2.0])\n",
    "\n",
    "        axs[j,i].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "        axs[3,i].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text(r'$\\frac{1}{N_{\\mathrm{trigger}}} \\mathrm{d}N_{\\mathrm{pairs}}$',fontsize=18)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass_2D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Missing Mass (z1,z1+z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.55, 0.65,0.70,0.8,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.hxmass_x,corr_D.hxmass,label='D',alpha=0.8)\n",
    "            axs[j,i].plot(corr_C.hxmass_x,corr_C.hxmass,label='C',alpha=0.8)\n",
    "            axs[j,i].plot(corr_Fe.hxmass_x,corr_Fe.hxmass,label='Fe',alpha=0.8)\n",
    "            axs[j,i].plot(corr_Pb.hxmass_x,corr_Pb.hxmass,label='Pb',alpha=0.8)\n",
    "            #axs[j,i].fill(corr_D.hxmass_x,corr_D.hxmass_mix,label='(mixed)',alpha=0.4)\n",
    "\n",
    "            plt.xlim([0.0,2.0])\n",
    "\n",
    "            axs[j,i].axvline(x=0.938,linestyle='--',color='black',alpha=0.6)\n",
    "            axs[3,i].xaxis.set_label_text(\"Missing Mass  [GeV]\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('MissingMass_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Invariant Mass (z1, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 3,sharex=True, sharey='row', figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.08, 0.15,0.30,0.5]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df_trigger['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df_trigger['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df_trigger['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df_trigger['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df_trigger['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df_trigger['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df_trigger['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "               \n",
    "        axs[j,i].plot(corr_D.hmass_x,corr_D.hmass,label='D')\n",
    "        axs[j,i].plot(corr_C.hmass_x,corr_C.hmass,label='C')\n",
    "        axs[j,i].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe')\n",
    "        axs[j,i].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb')\n",
    "        axs[j,i].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='mixed',alpha=0.4)\n",
    "        #axs[j,i].fill(corr_Fe.hmass_x,corr_Fe.hmass_mix,label='Fe (mix)',alpha=0.4)\n",
    "        \n",
    "        axs[j,i].axvline(x=0.770,color='black',alpha=0.6,linestyle='--')\n",
    "        axs[2,i].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text(r'$\\frac{1}{N_{\\mathrm{trigger}}} \\mathrm{d}N_{\\mathrm{pairs}}$',fontsize=18)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Mass_2D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Invariant Mass (z1, z1+z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.5,0.55, 0.65,0.70,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.hmass_x,corr_D.hmass,label='D')\n",
    "            #axs[j,i].fill(corr_C.hmass_x,corr_C.hmass_mix,label='C (mix)',alpha=0.4)\n",
    "            #axs[j,i].fill(corr_Fe.hmass_x,corr_Fe.hmass_mix,label='Fe (mix)',alpha=0.4)\n",
    "\n",
    "            axs[j,i].plot(corr_C.hmass_x,corr_C.hmass,label='C')\n",
    "            axs[j,i].plot(corr_Fe.hmass_x,corr_Fe.hmass,label='Fe')\n",
    "            axs[j,i].plot(corr_Pb.hmass_x,corr_Pb.hmass,label='Pb')\n",
    "            axs[j,i].fill(corr_Pb.hmass_x,corr_Pb.hmass_mix,label='mixed',alpha=0.4)\n",
    "\n",
    "            axs[j,i].axvline(x=0.770,color='black',alpha=0.6,linestyle='--')\n",
    "            axs[3,i].xaxis.set_label_text(\"Dipion Mass  [GeV]\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('Mass_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D t distribution vs z1+z2 and z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.5,0.55, 0.65,0.70,1.0]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z+z_asso>%2.2f and z+z_asso<=%2.2f'%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        minimum_numberofpairs = np.min([corr_D.numberofpairs,corr_C.numberofpairs, corr_Fe.numberofpairs, corr_Pb.numberofpairs])\n",
    "\n",
    "        \n",
    "        if( minimum_numberofpairs>20):  \n",
    "            axs[j,i].plot(corr_D.dipion_pt_x,corr_D.dipion_pt,label='D')\n",
    "            axs[j,i].plot(corr_C.dipion_pt_x,corr_C.dipion_pt,label='C')\n",
    "            axs[j,i].plot(corr_Fe.dipion_pt_x,corr_Fe.dipion_pt,label='Fe')\n",
    "            axs[j,i].plot(corr_Pb.dipion_pt_x,corr_Pb.dipion_pt,label='Pb')\n",
    "\n",
    "#            axs[j,i].axvline(x=0.4,linestyle='--',color='black',alpha=0.6)\n",
    "            axs[3,i].xaxis.set_label_text(\"dipion pT  [GeV]$\", fontsize=13)\n",
    "            axs[0,i].set_title('%2.2f < $z_{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "            axs[j,i].legend(loc='best',frameon=False)\n",
    "            axs[j,0].yaxis.set_label_text('%2.2f < $z_{1}+z_{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('t_2D_z1z2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4,sharex=True, sharey=True, figsize=(12,10), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "Edges = [0.4, 0.5,0.6,0.7,1.0]\n",
    "#Edges = [ -0.5,-0.2, 0.2, 0.5,1.0]\n",
    "bins = [(x, y) for (x, y) in zip(Edges[:-1], Edges[1:])]\n",
    "asso_Edges = [0.05,0.1, 0.15,0.25,0.4]\n",
    "asso_bins = [(x, y) for (x, y) in zip(asso_Edges[:-1], asso_Edges[1:])]\n",
    "\n",
    "\n",
    "for j, asso_bin in enumerate(asso_bins):\n",
    "    for i, trigger_bin in enumerate(bins):\n",
    "        query_trigger = 'z> %2.2f and z<= %2.2f '%(trigger_bin[0],trigger_bin[1])\n",
    "        query_asso = 'z_asso>%2.2f and z_asso<=%2.2f '%(asso_bin[0],asso_bin[1])\n",
    "        query_total = query_trigger + ' and '+ query_asso\n",
    "        print query_total\n",
    "    \n",
    "        corr_C = correlation(df['C_trigger'].query(query_trigger).shape[0], df['C'].query(query_total), df['C_mix'].query(query_total))\n",
    "        corr_D_C = correlation(df['D_C_trigger'].query(query_trigger).shape[0], df['D_C'].query(query_total), df['D_C_mix'].query(query_total))\n",
    "    \n",
    "        norma = np.sum(corr_D_C.corr_dphi)\n",
    "        corr_D_C.normalize(norma)\n",
    "        corr_C.normalize(norma)\n",
    "    \n",
    "    ##LEAD\n",
    "        corr_Pb = correlation(df['Pb_trigger'].query(query_trigger).shape[0], df['Pb'].query(query_total), df['Pb_mix'].query(query_total))\n",
    "        corr_D_Pb = correlation(df['D_Pb_trigger'].query(query_trigger).shape[0], df['D_Pb'].query(query_total), df['D_Pb_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Pb.corr_dphi)\n",
    "        corr_Pb.normalize(norma)\n",
    "        corr_D_Pb.normalize(norma)\n",
    "    \n",
    "    ##IRON\n",
    "        corr_Fe = correlation(df['Fe_trigger'].query(query_trigger).shape[0], df['Fe'].query(query_total), df['Fe_mix'].query(query_total))\n",
    "        corr_D_Fe = correlation(df['D_Fe_trigger'].query(query_trigger).shape[0], df['D_Fe'].query(query_total), df['D_Fe_mix'].query(query_total))\n",
    "        norma = np.sum(corr_D_Fe.corr_dphi)\n",
    "        corr_Fe.normalize(norma)\n",
    "        corr_D_Fe.normalize(norma)\n",
    "\n",
    "        comp_C = comparison(corr_C,corr_D_C)\n",
    "        comp_Fe = comparison(corr_Fe,corr_D_Fe)\n",
    "        comp_Pb = comparison(corr_Pb,corr_D_Pb)\n",
    "        \n",
    "        corr_D = correlation(df['D_trigger'].query(query_trigger).shape[0], df['D'].query(query_total), df['D_mix'].query(query_total))\n",
    "        corr_D.normalize(np.sum(corr_D.corr_dphi))\n",
    "        \n",
    "        axs[j,i].plot(corr_D.dipion_pt_x,corr_D.t,label='D')\n",
    "        axs[j,i].plot(corr_C.dipion_pt_x,corr_C.t,label='C')\n",
    "        axs[j,i].plot(corr_Fe.dipion_pt_x,corr_Fe.t,label='Fe')\n",
    "        axs[j,i].plot(corr_Pb.dipion_pt_x,corr_Pb.t,label='Pb')\n",
    "\n",
    "        plt.xlim([0.0,3.0])\n",
    "\n",
    "        axs[j,i].axvline(x=0.4,linestyle='--',color='black',alpha=0.6)\n",
    "        axs[3,i].xaxis.set_label_text(\"dipion pt [GeV]\", fontsize=13)\n",
    "        axs[0,i].set_title('%2.2f < $z^{1}$ < %2.2f'%(trigger_bin[0],trigger_bin[1]), fontsize=13)\n",
    "        axs[j,i].legend(loc='best',frameon=False)\n",
    "        axs[j,0].yaxis.set_label_text('%2.2f < $z^{2}$ < %2.2f'%(asso_bin[0],asso_bin[1]), fontsize=13)\n",
    "\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('dipion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking R2h as a function of z_tot instead of z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pb'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(12,6), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "\n",
    "for target in ['C','Fe','Pb']:\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.55,maxz=1.0,variable='z_tot')\n",
    "    axs[0].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso')\n",
    "    axs[1].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    \n",
    "axs[0].legend()\n",
    "axs[0].xaxis.set_label_text(\"z_2\", fontsize=13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results with and without z_tot<0.8 cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(12,6), gridspec_kw={'hspace': 0, 'wspace':0})\n",
    "\n",
    "for target in ['C','Fe','Pb']:\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso')\n",
    "    axs[0].errorbar(x,r,yerr=err,label=target,fmt='o',ms=8,lw=3,capsize=5)\n",
    "    r, err, x = getRatio(df[target],df['D_%s'%target],df_trigger['%s_trigger'%target],df_trigger['D_%s_trigger'%target],nbins=24,minz=0.05,maxz=.50,variable='z_asso',pair_cut=' and z_tot<0.8')\n",
    "    axs[1].errorbar(x,r,yerr=err,label=target,fmt='o',mfc='white',ms=8,lw=3,capsize=5)\n",
    "\n",
    "axs[1].set_title('with $z_1+z_2<$0.8', fontsize=13)\n",
    "axs[0].set_title('no cut ', fontsize=13)\n",
    "\n",
    "axs[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the dependency of the ratios on varios things like the charged of leading pion, subleading pion; Q2 and Nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],minz=0.1,trig_cut='z>0.5 and pid<0', pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],minz=0.1,trig_cut='z>0.5 and pid<0', pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "#plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid>0', minz=0.07,pair_cut='and pid >0 and pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi+ pi-',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x  = getRatio(df['GiBUU_C'],df['GiBUU_D'],df_trigger['GiBUU_C_trigger'],df_trigger['GiBUU_D_trigger'],trig_cut='z>0.5 and pid<0', minz=0.07,pair_cut='and pid <0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='pi- pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same sign results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='C, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Fe'],df['D_Fe'],df_trigger['Fe_trigger'],df_trigger['D_Fe_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='Fe, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],trig_cut='z>0.5 and pid>0', pair_cut='and pid >0 and pid_asso>0')\n",
    "plt.errorbar(x,r,yerr=err,label='Pb, pi+ pi+',fmt='o',ms=8,lw=3,capsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Varying Nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],query='and Nu>3.2')\n",
    "plt.errorbar(x,r,yerr=err,label='Nu>3.2',fmt='o',ms=8,lw=3,capsize=5)\n",
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],query='and Nu<3.2')\n",
    "plt.errorbar(x,r,yerr=err,label='Nu<3.2',fmt='o',ms=8,lw=3,capsize=5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, err, x = getRatio(df['C'],df['D_C'],df_trigger['C_trigger'],df_trigger['D_C_trigger'],query='and pid*pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='C, Lead, same sign',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "r, err, x = getRatio(df['Pb'],df['D_Pb'],df_trigger['Pb_trigger'],df_trigger['D_Pb_trigger'],query='and pid*pid_asso<0')\n",
    "plt.errorbar(x,r,yerr=err,label='Pb, Lead, same sign',fmt='o',ms=8,lw=3,capsize=5)\n",
    "\n",
    "plt.show()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z2 distribution breakdown for pi+ and pi- for all nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12, 10))\n",
    "\n",
    "for i, target in enumerate(['D','C','Fe','Pb']):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.hist(df[target].query('z>0.5 and pid_asso>0')['z_asso'], bins=100,range =(0,0.5),label='$\\pi^+$',alpha=0.5)\n",
    "    plt.hist(df[target].query('z>0.5 and pid_asso<0')['z_asso'], bins=100,range =(0,0.5),label='$\\pi^-$',alpha=0.5)\n",
    "\n",
    "    plt.title('%s, Conditional for $z_{1}>0.5$'%target)\n",
    "    plt.ylabel('pairs',fontsize=16)\n",
    "    plt.xlabel('$z_{2}$',fontsize=16)\n",
    "    plt.legend(frameon=False)    \n",
    "\n",
    "plt.savefig('ConditionalDistribution_z2_BothPions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# z distribution of triggers by charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12, 10))\n",
    "\n",
    "for i, target in enumerate(['D','C','Fe','Pb']):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.hist(df_trigger['%s_trigger'%target].query('z>0.5 and pid>0')['z'], bins=100,range =(0.5,1.0),label='$\\pi^+$',alpha=0.5)\n",
    "    plt.hist(df_trigger['%s_trigger'%target].query('z>0.5 and pid<0')['z'], bins=100,range =(0.5,1.0),label='$\\pi^-$',alpha=0.5)\n",
    "\n",
    "    plt.ylabel('pairs',fontsize=16)\n",
    "    plt.xlabel('$z_{1}$',fontsize=16)\n",
    "    plt.legend(frameon=False)    \n",
    "\n",
    "plt.savefig('Triggers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Pb'].query('z>0.5 and pid_asso>0')['P_asso'], bins=30,range =(0,1.5),label='pi+',alpha=0.5)\n",
    "plt.hist(df['Pb'].query('z>0.5 and pid_asso<0')['P_asso'], bins=30,range =(0,1.5),label='pi-',alpha=0.5)\n",
    "\n",
    "plt.title('Conditional distribution for $z_{1}>0.5$',fontsize=16)\n",
    "plt.ylabel('pairs',fontsize=16)\n",
    "plt.xlabel('$P_{2}$',fontsize=16)\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('ConditionalDistributionMomentum_Deuterium.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
